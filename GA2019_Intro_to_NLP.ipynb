{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GA2019 - Intro to NLP",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJuro/GA2019/blob/master/GA2019_Intro_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsOJt8xY__xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#surpresses lots of output\n",
        "%%capture \n",
        "!pip install whatthelang\n",
        "!pip install umap-learn\n",
        "!pip install eli5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dPu5YWq__xu",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Natural Language Processing & Machine Learning for Social Science Research\n",
        "\n",
        "## Globelics Academy 2019 - Computational Methods Part3\n",
        "### Roman Jurowetzki - 14/8 - 2019; roman@business.aau.dk\n",
        "\n",
        "- In this tutorial we will explore some relatively approachible techniques to utilize text as valuable data source in social science research. \n",
        "- The tutorial will use Python and several modern NLP and Machine Learning libraries to appraoch the problems\n",
        "- I will present 3 cases of typical applications that can be transferred to different reserach contexts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTGMYrV3__xv",
        "colab_type": "text"
      },
      "source": [
        "## Case 1: AirBnb in Mexico City\n",
        "\n",
        "AirBnb is collecting large amounts of text data every time the platform asks hosts and guests to review each other. This information is essential to create trust and to allow transactions on the platform. \n",
        "\n",
        "The textual data is valuable as it countatins lots of information. We can for example ask:\n",
        "\n",
        "- why did some one like or dislike a place?\n",
        "- do people describe cheaper stays differently than those that are expensive?\n",
        "\n",
        "We will use data form [InsideAirbnb](http://insideairbnb.com/ \"Airbnb\"), an independant platform that tracks Airbnb's influence on urban communities \n",
        "\n",
        "We will be using some out-of-the-box modules rather than train our classifiers from the ground up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBpqfHKh__xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the pandas library for handling CSVs and table-type data \n",
        "# import numpy for some (simple) linear algebra\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s8ulxdZ__xy",
        "colab_type": "code",
        "outputId": "5ee6d358-b4f5-4c82-ea4e-386dea9b72cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# download and unzip the data that we are going to use\n",
        "!wget https://storage.googleapis.com/roman-general/data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-12 09:59:34--  https://storage.googleapis.com/roman-general/data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61163094 (58M) [application/zip]\n",
            "Saving to: ‚Äòdata.zip‚Äô\n",
            "\n",
            "data.zip            100%[===================>]  58.33M  42.5MB/s    in 1.4s    \n",
            "\n",
            "2019-08-12 09:59:36 (42.5 MB/s) - ‚Äòdata.zip‚Äô saved [61163094/61163094]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_O6fmgVAYLP",
        "colab_type": "code",
        "outputId": "0cb782f1-7e39-49d1-d1a5-5242782d1bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/upwork_aom_300k.csv  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._upwork_aom_300k.csv  \n",
            "  inflating: data/reviews.csv        \n",
            "  inflating: __MACOSX/data/._reviews.csv  \n",
            "  inflating: data/spanish_revs.csv   \n",
            "  inflating: __MACOSX/data/._spanish_revs.csv  \n",
            "  inflating: data/listings.csv       \n",
            "  inflating: __MACOSX/data/._listings.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYXcZe6ZTMQL",
        "colab_type": "code",
        "outputId": "7efb5c55-e5ff-4c27-bd24-ba2711f334c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvw8pyeRQyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = pd.read_csv('reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4vbN2eTRRva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from whatthelang import WhatTheLang"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvnOR2ZsRV_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wtl = WhatTheLang()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2CcrV49R8p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_lang(text):\n",
        "    try: \n",
        "        return wtl.predict_lang(text)\n",
        "    except Exception:\n",
        "        return 'exp'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvJmYsfvRYPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6f1e6fe-43cc-4d11-9dbb-ca4fd59a2213"
      },
      "source": [
        "%time reviews['lang'] = reviews['comments'].map(lambda t: detect_lang(t))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.8 s, sys: 37.1 ms, total: 22.9 s\n",
            "Wall time: 22.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ifomnQ__x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open the reviews and reduce from 300k to random 10k rows\n",
        "\n",
        "reviews = pd.read_csv('reviews.csv')\n",
        "reviews = reviews.sample(50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4bqBPi__x2",
        "colab_type": "code",
        "outputId": "1b717dca-c1be-46e3-b364-50242d9a4242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>listing_id</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>reviewer_id</th>\n",
              "      <th>reviewer_name</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39554</th>\n",
              "      <td>5082965</td>\n",
              "      <td>112034833</td>\n",
              "      <td>2016-11-03</td>\n",
              "      <td>12433621</td>\n",
              "      <td>Taylor</td>\n",
              "      <td>Martha was a wonderful host! She was very acco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104278</th>\n",
              "      <td>11825682</td>\n",
              "      <td>121697959</td>\n",
              "      <td>2016-12-18</td>\n",
              "      <td>46306359</td>\n",
              "      <td>Rene</td>\n",
              "      <td>Carlos was very pollite,cool  and informative....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24119</th>\n",
              "      <td>2807016</td>\n",
              "      <td>92772761</td>\n",
              "      <td>2016-08-10</td>\n",
              "      <td>23397246</td>\n",
              "      <td>Gabrielle</td>\n",
              "      <td>We had a very positive experience at Lorena's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230801</th>\n",
              "      <td>20154527</td>\n",
              "      <td>231107818</td>\n",
              "      <td>2018-01-30</td>\n",
              "      <td>165147949</td>\n",
              "      <td>Ariel</td>\n",
              "      <td>El servicio cumpli√≥ nuestras expectativas. La ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266863</th>\n",
              "      <td>22230741</td>\n",
              "      <td>431804865</td>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>237673796</td>\n",
              "      <td>Ella</td>\n",
              "      <td>Oskar is very helpful, interested and generous...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        listing_id  ...                                           comments\n",
              "39554      5082965  ...  Martha was a wonderful host! She was very acco...\n",
              "104278    11825682  ...  Carlos was very pollite,cool  and informative....\n",
              "24119      2807016  ...  We had a very positive experience at Lorena's ...\n",
              "230801    20154527  ...  El servicio cumpli√≥ nuestras expectativas. La ...\n",
              "266863    22230741  ...  Oskar is very helpful, interested and generous...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcCcI5mi__x5",
        "colab_type": "text"
      },
      "source": [
        "#### Language detection\n",
        "First we need to detect the language of the review, as we will only focus on the English reviews\n",
        "\n",
        "The `langid` library is a good choice. It's easy to use and fast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1amPmxu__x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the library\n",
        "\n",
        "import langid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2It4TLm2__x7",
        "colab_type": "text"
      },
      "source": [
        "Text data is messy: Sometimes people just add üòâ or somewhint completely different. This is where the model gets into trouble and returns errors.\n",
        "To prevent that form happening, we will write a little function that turns exceptions into \"exp\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A5AmRGA__x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining a little exception-handling function for the language detector\n",
        "\n",
        "def detect_lang(text):\n",
        "    try: \n",
        "        return langid.classify(text)[0]\n",
        "    except Exception:\n",
        "        return 'exp'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl85RKiC__x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we apply the language detection function\n",
        "reviews['lang'] = reviews['comments'].apply(detect_lang)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjsBH1V-__yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now, we filter out the spanish reviews\n",
        "english_reviews = reviews[reviews['lang'] == 'en']\n",
        "english_reviews = english_reviews.sample(n=25000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C12yQvlB__yF",
        "colab_type": "text"
      },
      "source": [
        "#### Sentiment analysis - easy version\n",
        "In this part of the tutorial we will be using a pre-trained Spanish sentiment analysis model from https://github.com/aylliote/senti-py to figure out how people feel about their stays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqlUOegW__yF",
        "colab_type": "code",
        "outputId": "02e32641-3d43-4093-b010-8ea56b066828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# We import and instantiate the classifier\n",
        "  >>> import nltk\n",
        "  >>> nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBwMmxg__yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try it out\n",
        "sentences = [\"VADER is smart, handsome, and funny.\", # positive sentence example\n",
        "...    \"VADER is smart, handsome, and funny!\", # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
        "...    \"VADER is very smart, handsome, and funny.\",  # booster words handled correctly (sentiment intensity adjusted)\n",
        "...    \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
        "...    \"VADER is VERY SMART, handsome, and FUNNY!!!\",# combination of signals - VADER appropriately adjusts intensity\n",
        "...    \"VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\",# booster words & punctuation make this close to ceiling for score\n",
        "...    \"The book was good.\",         # positive sentence\n",
        "...    \"The book was kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n",
        "...    \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
        "...    \"A really bad, horrible book.\",       # negative sentence with booster words\n",
        "...    \"At least it isn't a horrible book.\", # negated negative sentence with contraction\n",
        "...    \":) and :D\",     # emoticons handled\n",
        "...    \"\",              # an empty string is correctly handled\n",
        "...    \"Today sux\",     #  negative slang handled\n",
        "...    \"Today sux!\",    #  negative slang with punctuation emphasis handled\n",
        "...    \"Today SUX!\",    #  negative slang with capitalization emphasis\n",
        "...    \"Today kinda sux! But I'll get by, lol\" # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
        "... ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z2VXfW1__yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj9YagRlTSDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "c98ee26c-f79d-44da-f326-98574c1e7c7f"
      },
      "source": [
        "for sentence in sentences:\n",
        "  print(sentence)\n",
        "  ss = sid.polarity_scores(sentence)\n",
        "  print(ss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VADER is smart, handsome, and funny.\n",
            "{'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
            "VADER is smart, handsome, and funny!\n",
            "{'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
            "VADER is very smart, handsome, and funny.\n",
            "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n",
            "VADER is VERY SMART, handsome, and FUNNY.\n",
            "{'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n",
            "VADER is VERY SMART, handsome, and FUNNY!!!\n",
            "{'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n",
            "VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\n",
            "{'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n",
            "The book was good.\n",
            "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
            "The book was kind of good.\n",
            "{'neg': 0.0, 'neu': 0.657, 'pos': 0.343, 'compound': 0.3832}\n",
            "The plot was good, but the characters are uncompelling and the dialog is not great.\n",
            "{'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n",
            "A really bad, horrible book.\n",
            "{'neg': 0.791, 'neu': 0.209, 'pos': 0.0, 'compound': -0.8211}\n",
            "At least it isn't a horrible book.\n",
            "{'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n",
            ":) and :D\n",
            "{'neg': 0.0, 'neu': 0.124, 'pos': 0.876, 'compound': 0.7925}\n",
            "\n",
            "{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Today sux\n",
            "{'neg': 0.714, 'neu': 0.286, 'pos': 0.0, 'compound': -0.3612}\n",
            "Today sux!\n",
            "{'neg': 0.736, 'neu': 0.264, 'pos': 0.0, 'compound': -0.4199}\n",
            "Today SUX!\n",
            "{'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n",
            "Today kinda sux! But I'll get by, lol\n",
            "{'neg': 0.195, 'neu': 0.531, 'pos': 0.274, 'compound': 0.2228}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RbSjo8z__yR",
        "colab_type": "text"
      },
      "source": [
        "**speed issues**\n",
        "\n",
        "Preprocessing of the text and prediction takes some time, unfortunately. These are, after all, heavy processes.  We will use simple multiprocessing (using all cores of the CPU) to optimize performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbnImID__yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Engage multiprocessing\n",
        "\n",
        "from multiprocessing import Pool\n",
        "p = Pool()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2a88b473-d2d0-4426-8073-540e507e6646",
        "id": "xPsF0bVkUKE2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "# Calculate the scores (sentiment analysis) that will take around 4 Minutes\n",
        "\n",
        "english_reviews['score'] = p.map(sid.polarity_scores, english_reviews['comments'])\n",
        "english_reviews['score'] = english_reviews['score'].map(lambda x: x['compound'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 138 ms, sys: 63.9 ms, total: 202 ms\n",
            "Wall time: 15.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDYK7Zmf__yX",
        "colab_type": "code",
        "outputId": "76353ced-a8a4-4bea-f835-40cc95021676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's print the reviews starting with the top 20 negative ones\n",
        "\n",
        "for i in english_reviews.sort_values('score', ascending=True)['comments'][:20]:\n",
        "    print(i)\n",
        "    print('\\n')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I will leave the perfect description regarding this place: \n",
            "1. we were excited there was a doorman because that meant to us that the building was going to be nice, but the building had a smell, sofas in the ‚Äòlobby‚Äô are worn out, ugly in general. \n",
            "2. the apartment has a nice view but using the balcony is unpleasant since there is nothing there, except an old table and chairs.  \n",
            "3. the apartment has a smell. in general the apartment‚Äôs walls, windows, and kitchen are old \n",
            "4. we had NO hot water during our stay. contacted the host but nothing was solved. had to shower with cold water at 5:00am the day we were leaving to the airport.  \n",
            "5. there is no AC, and we knew that before confirming our stay, but the apartment is HOT. there is 1 standing fan in the bedroom. \n",
            "6. you won‚Äôt want to sit in the chairs and the sofas since they are stained, worn out, and look dirty. \n",
            "7. good location\n",
            "8. in order to leave you have to leave the key in the apartment, but need the key to get out of the building since the doorman cant open the door for you.. we had to run back up to get the key, open the door, and run back up to leave the key. \n",
            "9. no outlets near the bed. \n",
            "10. the bathroom incredibly poor lighting. \n",
            "\n",
            "I dont want to sound so negative, but I want others to know what to expect.\n",
            "\n",
            "\n",
            "** TERRIBLE ** DO NOT BOOK THIS PLACE. ** DEATHTRAP ** This is a hacked unit in a BUSINESS PARK surrounded by small businesses. I knew something was wrong when I never encountered anyone in the complex.  It felt so unsafe. If you encountered a problem, there was literally no one around that could help you. Wifi was spotty as well. The front door resembles a prison cell door and was very hard to open. And there isn't a second exit from the unit (b/c I think it's ILLEGAL).  I pray nobody ever has an emergency in this unit (and remember that earthquakes are frequent in CDMX-- I felt tremors my entire time there) because I think it will be tragic. \n",
            "\n",
            "Because it's in a BUSINESS PARK there is no community to regulate noise. There was a party going in the parking lot of a club behind the unit on a Saturday night until 3 AM. And the little girl who lives in the unit next door screams loudly when she leaves her apartment every morning around 7 or 8 in the morning. When I pointed this out to Ricardo, and that his listings says quiet hours from 9 to 9, he told me he can't control these things and instead of refunding my money (I left halfway through my stay b/c I feared for my safety) he offered me earplugs and alcohol. \n",
            "\n",
            "Also safety is a concern. In addition to there being no one around, all of the gates open from the inside. All you have to do (and what you are instructed to do at checkin) is reach over and unlock it. If you can do it, chances are others can too. \n",
            "\n",
            "This was THE MOST DISAPPOINTING EXPERIENCE I HAVE EVER HAD WITH AN AIRBNB RENTAL.\n",
            "\n",
            "\n",
            "I usually don't want to be mean to write any bad reviews. This time my family's bad experience was just more than enough. \n",
            "\n",
            "No need to elaborate the whole story in details. Generally please be prepared to deal with a dishonest host who told a lie to the Airbnb to justify her unprepared dirty room. The shocking disgusting details drove my family sleepless. Forgotten socks, stained linens, filthy kitchen, smelly toilets, leaked laundry room,  garbage, abandoned coca cola bottles, scattered spoons on counter top, so on and on. No clear check in instructions either, you need to deal with a cleaning lady who neither speak English nor care the business at all. Since it is not a motel price, you might be surprised at what you get! \n",
            "\n",
            "Lesson learnt the hard way: Choose a honest host is much more important than choosing the room itself. Don't be cheated by the photos, what you see in real might be so different, what you feel is even worse. The so called view with Carso is a constructing building directly out of your window! \n",
            "\n",
            "Tips:  Even with all the photo proofs and time-line messages, the process to challenge an bad host and getting Airbnb mediator involved is really efforts consuming. It doesn't deserve your family's precious vacation time to deal with all the headaches. There are plenty of Airbnbs in this area.  Avoid this one!\n",
            "\n",
            "\n",
            "NOT RECOMMENDED. NO SE RECOMIENDA. Dirty, poorly managed, not supplied with necessities (pillowcases, towels, toilet paper). Sucio, mala gesti√≥n, suministros inadecuados. \n",
            "\n",
            "Worst Airbnb I've stayed in: not ready for an hour after agreed time (4pm). Hadn't been cleaned: there was dirty underwear on hammock, broken glass on patio, filthy floors, no pillowcases on bed, dirty sheets left out for futon. UNCOMFORTABLE: we were given one bath towel for three people (no others) and one roll of toilet paper for whole apartment. There were no bath mats, no trash can in kitchen.  The manager Carlos was not pleasant or helpful--we had to repeatedly ask to have situation remedied.  \n",
            "\n",
            "Great neighborhood\n",
            "\n",
            "\n",
            "Good location, basic but sufficient apartment. However the hosts made my experience very negative unfortunately due to terrible communication and bad check in experience. Juan Alvaro was extremely slow at responding to messages before my arrival, and did not give accurate check in information until a few hours before I was due to arrive (and was already flying, so had no internet) . I specifically paid for an extra night so I could arrive at the property at 5:30am which he told me was fine. However nobody answered the door, and neither he or his friend who lived in the apartment, Gustavo, responded to calls or messages. I was left waiting on the street for 45 minutes while it was still dark and I did not feel safe at all. I recieved no apology from Juan Alvaro and he never repsonded to my messages. Then two days into my stay Gustavo told me they needed to cancel my reservation and that I needed to contact Juan. Juan never responded to my messages and in the end I had to message Gustavo who told me that things had been resolved.\n",
            "\n",
            "\n",
            "We had a very traumatic experience.\r\n",
            "\r\n",
            "We had booked the the place because of the good reviews and the pretty pictures of the place. \r\n",
            "The place looked indeed as described in the images BUT the insonorisation was extremely poor. We arrived in DF (not the safest city in the world ) in the afternoon. When we arrived, the next door neighbor was playing music full blast and the walls were shaking with the basses. We kindly asked him to lower but he refused. My friend suffers from anxieties with noise so after 30 min we had to look for a hotel to spend the night because the noise level was getting worst and worst. \r\n",
            "\r\n",
            "We contacted Karla that at the beginning was relatively responsive. When we told her we have to look for a hotel because the noise was making it impossible to relax and asked if she could be accommodating with regarding the rest of our stay, she immediately stopped answering our emails, leaving us alone to deal with the situation. \r\n",
            "\r\n",
            "The day after we try to come back because we could not afford to stay again at the hotel but the entrance guard refused to give us back the keys. We could not contact Karla immediately bc we had no Internet access with our us phone and had to deal with the guard with little Spanish to explain him the situation. We got very uncomfortable and left again with our luggage to a hotel nearby.\r\n",
            "\r\n",
            "Not recommending the place\n",
            "\n",
            "\n",
            "Nice place, but Marco took advantage of us. Upon checking out I informed him that one of the wine glasses had broken when we were washing it, and offered to pat for it. But 6 days later we get a bill for over $70 USD!!! He claimed that he had to charge us for a full 6 set of wine glasses, even though not all of his wine glasses were matching. He also was claiming one of the stove knobs was broken, even though I pointed that out to his maintenance guy when he came over. Worst part is he accused us of not tipping the maintenance guy, even though we had little notice he was coming over, and we did not have any spare change at the time. So, beware, as a single broken wine glass could cost you quite a bit.\n",
            "\n",
            "\n",
            "Not a nice place at all. Disgusting place \n",
            "\n",
            "I stayed here for 6 nights by myself.\n",
            "This one basically is not prepared for having a guest at the moment. \n",
            "\n",
            "There‚Äôs a lot of problem which cannot be solved while i was staying.\n",
            "\n",
            "1. Security is the worst problem here. Windows is not locked which means anyone can come inside while guest is not here. Even the door for main bedroom also not locked from outside.(possible to lock from inside) So I made my own security system. Ha-ha-ha\n",
            "2. Smells ... from drain in the bathroom and sink of kitchen was awful. Even during i was sleeping in the bed. Particularly it was horrible when i was back this flat after good time out side.  Because I closed windows for about 10 hours. It made me throw up. \n",
            "3. Bugs... could be your friends. Which one do you like the most? Ants, spiders, cockroaches, flying green one.Anonymous tiny crawling grub on the bed. I met dead insects every morning.( round and dark brown color one) \n",
            "4. Animal hair... was everywhere. On the floor, sofa, table, towels even bed sheets and blankets. (I changed Bed sheets and towels on the first night, but it was the same. I assume she raises the animals in the house.( dogs or cats or both) all of my clothes that i was wearing in this place was covered white hair. I might have swallowed some. \n",
            "5. Utensils was not enough for cooking. There‚Äôs no cutting board. She brought me big glass dish to use as cutting board. Eventually, i cut my finger because it was so slippery to cut something on this. \n",
            "6. It was NOT clean at all, actually was dirty. It seemed like empty for a long time. \n",
            "7. Host, the guy who i was contacted is not in M√©xico, he is in Europe. So actual host was old lady. I really wanted to move out on the first day, this guy not allowed and asked to his aunt to clean up who was so gasping when she arrived here(3rd floor) for cleaning next day that I asked to him. \n",
            "8. Bed is just a mattress not a bed.  \n",
            "9. Location was not good. It took 20   minutes to zocalo by metro. But it was inconvenience to get to other attractions.\n",
            "\n",
            "\n",
            "My husband and I were very excited to stay here and to have found something in Polanco for this price. Alejandro was very forthcoming while we were booking, but unfortunately the experience itself was not good. I only give it 2 stars because the doorman was very nice and helpful- he should get a raise! Not the owner of this clearly run down hotel, probably making a profit. Unfortunately this place was not at all worth the price we paid, for several reasons: -it‚Äôs on the first floor of a building which is clearly being used as a hotel (at least part of it - it seemed the upper floors could have been actual apartments). It had the feeling of a very old fashioned hotel in poor condition. It didn‚Äôt feel like an apartment at all. It smelled of mole everywhere and had awful carpeting on most of the floor. -it was VERY claustrophobic. While there are windows in the living room and bedroom, both face directly into another building, with at least 4 floors above so nearly no light got in. The bedroom was even worse as there is a wall right outside the window that blocks light. Several days I slept 3 or so hours extra because i couldn‚Äôt even tell it was daytime!! -it was missing a few things: the apartment had nothing to help with cooking basics- no oil, salt, pepper, and not even a sponge or dish soap. It also had no shampoo, even though the description does state that shampoo is included. That‚Äôs a real pain when you‚Äôre staying somewhere for s week and have to go out to do errands like buying dish soap and shampoo. We contacted the host and asked where those items were- he informed us that they were not included and told us there were shops nearby where we could buy them ourselves. I would ask him that he then change the description to be more accurate. -there was a cleaning service every day which changed our towels (I think although they never seemed very clean) and vacuumed. They also ‚Äúreplaced‚Äù our toilet paper- but they would only leave rolls that were ALMOST run out. It was very strange. Once we came back in the evening and immediately ran out of toilet paper because the one they put it in had about 8 squares left. Very odd and did not make us feel good about the place!! -the lock on the apartment door was barely a bedroom lock. It was a simple push in lock, and we did not feel safe leaving any valuables there during the day- not because we distrusted the staff or anything, but simply because other guests could also wander by. It didn‚Äôt feel secure. -overall it just felt very depressing. We wanted to spend as little time there as possible. Every day we packed for the whole day and stayed out until we were ready to go to sleep (at least the bed was...\n",
            "\n",
            "\n",
            "Location was great but host does not really care for guests. We texted far in advance and several hours before but had to wait outside for 30min in the rain and almost booked another place. If host sent us instructions in advance we could have entered ourselves. Then instead of apologising he blamed that his phone notifications didnt work. We thought it was weird but didnt really care. Then the second day the showers stopped working for 3 days. I didnt shower for 2 days then third day could use another bathroom. He first accepted to refund 20% but then before doing it, in a sneaky way wanted me to write a 5 star review first. Made me feel he tried to trick me by getting a good review then not refunding. When I obviously refused, he said he was not responsible for the showers not working and \"the inbox airbnb app not working for him\"? If he is not responsible for amenities and check in, then who is? The communication and dishonesty was the worst part, we didn't mind the rest.  Our stay in Mexico city was amazing, but because we dont want to reward dishonesty we prefer to rent a different place next time. Roma is def the place to be. Have fun wherever you go.\n",
            "\n",
            "\n",
            "The apartment is great but not in top shape. Bad sound insulation in both bedrooms. Shower difficult to operate. Water pressure to low at times form the washing machine. Blind in the kitchen cannot go up completely.\r\n",
            "\r\n",
            "The location is quite a distance from the zocalo (parque centenario) and also far from any metro station.\r\n",
            "\r\n",
            "Overall it is too expensive for what it is.\n",
            "\n",
            "\n",
            "I don‚Äôt even know where to start... DO NOT STAY HERE. Unless the listing is updated - which I hope and pray that it is. \n",
            "This airBnB boasts an amazing rooftop area with a jacuzzi, lounge area and tables... NONE of which were available because the rooftop is a construction zone and by looking back on other people‚Äôs reviews of the place, i see that it had been out of commission since AT LEAST December! The host did not update his post to reflect that nor did he make any attempts to let us know that area (which was a huuuuge selling point for us) was unavailable. As for the indoor pool, it‚Äôs there,yes. The indoor jacuzzi was bone dry and when I messaged David about it, he suggested I should contact maintenance - instead of offering to do it himself. The ‚Äògame room‚Äô is one ping pong table without a net or paddles in sight. For the sauna, you have to make an appointment to use it ahead of time, if it‚Äôs even working. \n",
            "\n",
            "As for the room it‚Äôs self, the door is locked with a code which was provided to us ahead of time. Check in was smooth and the security guards down stairs were helpful. The apartment is okay but lacking after reading the description of his place. The ‚Äòhigh quality utensils‚Äô were in fact nothing special, there was NO salt, pepper or oil available for cooking. Also NO fine Mexican wines or spirits as promised. The ‚Äòamazing view‚Äô was actually NOT that great, there were no ‚Äòlocal guide books‚Äô, the books there very general and NOT tailored to Roma Norte at all. AC only in the living room and the cool air did not reach the bedroom. The TV was very nice and the WiFi worked, on the plus side. David was rude and unhelpful when I brought these things to his attention. Overall this was a bad experience, even worse because it was our honeymoon. \n",
            "\n",
            "I Would NOT recommend to others. Spend your money elsewhere. Don‚Äôt get catfished by this listing like we unfortunately did.\n",
            "\n",
            "\n",
            "If you are more than 2 people DONT RENT HERE. The other 2 beds that he is saying that he has are bunch of palletes together with a terrible mattress, and the worst of all, only half of your body fits in those palletes! All the place smelled like gas (and it stinks). Not a very safe neighborhood, and I think the worst of all is dealing with the host. Its just terrible. The value of this apartment is not even close of what he is charging. Ive stayed in a lot of apartments around mexico city, and this is the most expensive one (and the apartment is not even cosy). He is charging me extra because check out was terrible, he displays a code to unlock the keys in his profile but is not the correct one. I tried to call him and he doesnt answer, not even the texts. For me Its just INCREDIBLE that he doesnt have extra set of keys!! The worst experience Ive ever had in airbnb.\n",
            "\n",
            "\n",
            "I was contacted by the host through (Hidden by Airbnb) and asked what time I would arrive.  I advised her that we would get there around 545pm to 6pm.  Upon arrival a man was still mopping the floor. I couldn't even use the restroom because they were still cleaning.  I had to just leave my stuff and come back later. This should have been done before the 2pm checkin time, and definitely before 6pm.  The apartment and building was nice and historic with a good view from the room and roof.  However if don't like to be annoyed then I would look for another place.  The host contacted me too many times through (Hidden by Airbnb) .  The host should of contacted me through Airbnb, and asked first if I minded being contacted through (Hidden by Airbnb) .  The most irritating message was around 9m she asked me what time I would checkout.  This should matter if checkout is at 11am.  Then it all made sense when at (Phone number hidden by Airbnb) am a woman came and knocked on the door.  I told her to wait a minute since it was still before 11am and my wife was gathering her things.  Then the woman unlocked the door and opened it wide open anx just stood there.  My wife and I could have been undressed or something worse.  The host's message the night before made sense, they want you out as soon as possible.  Imagine if every time you rent on Airbnb or a hotel they are asking you the night before when you are going to leave before it it morning.  And to add more irritation they come and open your door wide open 5 minutes before checkout and just stand there watching you.  I shouldn't have been payed to stay there with the experience I had. My wife and I both felt like our privacy was invaded by the host and her employees.  My wife and I have stayed used Airbnb numerous other times, and this time has been the worse by far!\n",
            "\n",
            "Swap to English\n",
            "\n",
            "El anfitri√≥n me contact√≥ a trav√©s de (Hidden by Airbnb) y me pregunt√≥ a qu√© hora llegar√≠a. Le aconsej√© que llegar√≠amos entre las 545 y las 6 de la tarde. A su llegada, un hombre todav√≠a estaba limpiando el suelo. Ni siquiera pod√≠a usar el ba√±o porque todav√≠a estaban limpiando. Tuve que dejar mis cosas y volver m√°s tarde. Esto deber√≠a haberse hecho antes de las 2 pm hora de registro, y definitivamente antes de las 6 pm. El apartamento y el edificio eran bonitos e hist√≥ricos, con una buena vista desde la habitaci√≥n y el techo. Sin embargo, si no me gusta estar molesto, buscar√≠a otro lugar. El anfitri√≥n me contact√≥ muchas veces a trav√©s de (Hidden by Airbnb) . El anfitri√≥n me contact√≥ a trav√©s de Airbnb y me pregunt√≥ primero si me importaba que me contactaran a trav√©s de (Hidden by Airbnb) . El mensaje m√°s irritante fue alrededor de los 9 m. Me pregunt√≥ a qu√© hora me gustar√≠a ir. Esto deber√≠a importar si la salida es a las 11 am. Entonces todo tuvo sentido cuando, a las (Phone number hidden by Airbnb) am, una mujer vino y llam√≥ a la puerta. Le dije que esperara un minuto ya que a√∫n era antes de las 11 am y mi esposa estaba recogiendo sus cosas. Luego la mujer abri√≥ la puerta y la abri√≥ de par en par, y se qued√≥ all√≠. Mi esposa y yo podr√≠amos haber estado desnudos o algo peor. El mensaje del anfitri√≥n la noche anterior ten√≠a sentido, quieren que salgas lo antes posible. Imag√≠nese si cada vez que alquila en Airbnb o en un hotel le pregunten la noche anterior, cuando vaya a salir antes de la ma√±ana. Y para agregar m√°s irritaci√≥n, vienen y abren la puerta completamente abierta 5 minutos antes de la salida y se quedan ah√≠ mir√°ndote. No deber√≠a haberme pagado para quedarme all√≠ con la experiencia que tuve. Mi esposa y yo sentimos que nuestra intimidad fue invadida por el anfitri√≥n y sus empleados. Mi esposa y yo hemos estado usando Airbnb muchas otras veces, ¬°y esta vez ha sido la peor por mucho!\n",
            "\n",
            "\n",
            "This has been by far one of my worst Airbnb experiences ‚Äî the only bad one, really:\n",
            "\n",
            "When I checked in, the apartment had no hot water, so I was unable to take a shower. I messaged the host through Airbnb to report this, and after hours, the host said that this issue had been resolved (I was already out of the apartment, so I was unable to verify this).\n",
            "\n",
            "Next morning, when I wanted to shower, there was still no hot water, so I was (for the 2nd day) unable to shower. I contacted again the host at approximately 8am, and then multiple times after that. The host never replied.\n",
            "\n",
            "To make things worse, the host requested an in-person checkout. However, 30 minutes after the agreed time, the host had not showed up. Since I was traveling, I had no phone coverage, so I had to ask a stranger for a phone to call te host (because they didn‚Äôt reply any of my multiple Airbnb messages). Finally they answered the phone, told me that they were on their way, and that when they showed up they would help me fix the hot water. When the host arrived, they said they were going to be unable to fix the hot water, and simply apologized. Regardless, it was so late that I even if they had fixed the issue, I would have had no time to shower.\n",
            "\n",
            "Finally, there was a small dead cockroach in the bathroom.\n",
            "\n",
            "\n",
            "Don't stay here!! What a terrible experience. The host was 3 hours late and didn't tell me until I was already at the apartment at my scheduled time. He then claimed he was going to be 1 hour late. I waited outside. 2 hours later he told me to cancel and go to a hostel and then didn't respond for another hour. 3 hours later as I waited and wasted my whole day in Mexico City (first and only time) he showed up when it was already night time and proceeded to put me in the wrong (small) room when I had paid for the large with private bath. After my long trek, I asked for drinking water provided and he said he ran out and would come back with some. As I appreciate he was quick coming back, it was just one problem after another. I had gotten settled into the smaller (wrong) room, then he forced me move because he said he booked someone else in that room. After he rushed to clean it, I moved to the original room I had paid for, but all of it was extremely disorganized and just poor hosting on his part. He should NOT be a Super host. What a shame and terrible first glance of what I hear to be a fun and beautiful city.\n",
            "\n",
            "\n",
            "The host did make me feel welcome, but the place in general was horrible. Even the host said that it was ugly before he started showing me the apartment. Inside the apartment was not awful but the apartment building was very bad and there were holes on the floor, the building was scary and dark and it seemed like there was not a lot of security. \n",
            "\n",
            "\n",
            "One person could take a shower with about 3 minutes worth of \"warm\"--not \"hot\"--water. The second person had zero hot/warm water--therefore the only option was an ice cold shower (not a pleasant thing when the outside temperature was quite chilly, and the apartment was quite chilly, too, with no thermostat/heat). For us, this was an absolute deal-killer in terms of \"being on vacation,\" really enjoying a Mexico City vacation, really enjoying this rental, the whole thing, ultimately prompting us to re-book our flights and head home one day early. To my mind, it's absolutely inexcusable that a rental that has no hot water and essentially no warm water could even be listed on Airbnb--unless it is a listing for some sort of rental or locale where such a thing is expected or the norm. And if there was a rental where there was no hot water and essentially no warm water and such a thing is not expected or the norm, or there's any possible uncertainly about the renter's expectations in that regard, then I would expect some sort of bold/caps-type message that screams \"no hot water/ice cold showers.\" I wrote to Hugo about this  and his response was that ‚Äúthe water is a problem in the city that is on reparation and the water pressure is not good and it is need for hot water, there is a trick you flush the water toilet and the pump starts working and hot water easy will be ‚Ä¶.‚Äù Well, first, at least in part this misunderstands the problem. Water pressure and water temperature are different, and there was no water pressure issue in the apartment. Also, there was no problem with water flow to the apartment, so this had nothing to do with Mexico City water repairs. The issue was hot/warm water, and even if there is some alleged ‚Äútrick‚Äù for getting hot/warm water out of the showerhead, how could this apartment possibly be rented without making that abundantly clear‚Äîon the front end of the rental? We never would have rented this apartment had this been made clear, and I doubt anyone else would, either ....\n",
            "\n",
            "\n",
            "Despite the great location and safe building, I was very disappointed by this listing. The walls and ceilings were dirty, the bedsheets were ripped, wrinkled and old and the unit was very hot. The terrace, which is heavily featured in the listing‚Äôs profile, looks like an abandoned ghost town and has been ‚Äúclosed for maintenance‚Äù for several months. Difficulty confirming the reservation and contacting the host on the date of my check-in further contributed to the unpleasant stay.\n",
            "\n",
            "\n",
            "There was no storage space at all - neither in the room itself nor in the bathroom. Not even really space to leave a suitcase in the room or to open it. The closet was packed with the host‚Äòs own clothes so this couldn‚Äòt be used either. The bedside table was full of books. I didn‚Äòt have ANY space at all \n",
            "\n",
            "There were black hair in the sleeping room and in the living room - and I‚Äòm blond.\n",
            "When checking in the host didn‚Äòt even give me the wifi details and didn‚Äòt answer for hours when I was asking for it.\n",
            "\n",
            "On top of it all the host was accusing me one day AFTER I left of having destroyed a piece of furniture and asked me to pay like 100 Dollars for it?!? Something like that Never happened to me in an Airbnb!\n",
            "\n",
            "Casi no hubo nada de espacio en la habitaci√≥n a dejar sus cosas o abrir su maleta. El closet estuvo llen√≠simo de ropa de la anfitriona - tampoco fue posible usarlo. \n",
            "La misma cosa en el ba√±o. \n",
            "La mesita de noche tambien estuvo llena de libres - imposible usarla. No hubo nada pero NADA espacio.\n",
            "Encontr√© cabello negro en el ba√±o y tb en la rec√°mara - y yo tengo el cabello rubio.\n",
            "Cuando llegu√© la anfitriona se fue sin darme los datos para tener acceso al wifi y no respondi√≥ a mensajes por horas cuando le pregunto por estos.\n",
            "Adem√°s me acus√≥ un d√≠a DESPU√âS de mi salida de haber destruido un mueble y quiso que le paga 100 d√≥lares?!?\n",
            "Nunca me pas√≥ algo parecido en un Airbnb!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR-MVhDh__ya",
        "colab_type": "text"
      },
      "source": [
        "#### Bringing in additional data for analysis\n",
        "Now we can use additional information that we have on the houses to actually use our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32FS65D__yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we open the listings data\n",
        "listings = pd.read_csv('listings.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnRi_XsO__yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can calculate the median scores for all rooms\n",
        "scores = pd.DataFrame(english_reviews.groupby('listing_id').median()['score'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O93fCVdx__yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We merge the listing data with our median reviews\n",
        "merged = pd.merge(listings, scores, how='inner', left_on='id', right_on='listing_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyHDKsew__yo",
        "colab_type": "code",
        "outputId": "6c73664d-ee63-4fb6-bace-f1384de37228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "merged.info()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6284 entries, 0 to 6283\n",
            "Data columns (total 17 columns):\n",
            "id                                6284 non-null int64\n",
            "name                              6282 non-null object\n",
            "host_id                           6284 non-null int64\n",
            "host_name                         6284 non-null object\n",
            "neighbourhood_group               0 non-null float64\n",
            "neighbourhood                     6284 non-null object\n",
            "latitude                          6284 non-null float64\n",
            "longitude                         6284 non-null float64\n",
            "room_type                         6284 non-null object\n",
            "price                             6284 non-null int64\n",
            "minimum_nights                    6284 non-null int64\n",
            "number_of_reviews                 6284 non-null int64\n",
            "last_review                       6284 non-null object\n",
            "reviews_per_month                 6284 non-null float64\n",
            "calculated_host_listings_count    6284 non-null int64\n",
            "availability_365                  6284 non-null int64\n",
            "score                             6284 non-null float64\n",
            "dtypes: float64(5), int64(7), object(5)\n",
            "memory usage: 883.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBNQ6Pj__yr",
        "colab_type": "code",
        "outputId": "38be6fee-c0b5-484d-e9f8-bab4b6b2b4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# Now we can for example explore median scores for the different parts of town\n",
        "\n",
        "merged.groupby('neighbourhood').median()['score'].sort_values()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neighbourhood\n",
              "Cuajimalpa de Morelos     0.796300\n",
              "La Magdalena Contreras    0.815225\n",
              "Tlalpan                   0.852500\n",
              "Venustiano Carranza       0.878475\n",
              "Iztacalco                 0.880800\n",
              "√Ålvaro Obreg√≥n            0.890300\n",
              "Azcapotzalco              0.895600\n",
              "Gustavo A. Madero         0.897900\n",
              "Iztapalapa                0.903800\n",
              "Benito Ju√°rez             0.903950\n",
              "Miguel Hidalgo            0.905000\n",
              "Xochimilco                0.930000\n",
              "Cuauht√©moc                0.931000\n",
              "Coyoac√°n                  0.931775\n",
              "Tl√°huac                   0.966800\n",
              "Name: score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2xHT7NE__yu",
        "colab_type": "text"
      },
      "source": [
        "## Case 2: Explaining text-predictions\n",
        "\n",
        "Machine learning models are often considered \"black-boxes\". Especially more complex models (e.g. XGboost, SVMs, Neural Networks) don't let us directly see what they learn and how they make decisions.\n",
        "In the past few years, the discussions on explainable AI have spurred lots of research in that area and today we have some ways to understand how machines decide (see this excellent book for details: https://christophm.github.io/interpretable-ml-book/)\n",
        "\n",
        "In this short case, we will use the data from the previous example to train up a model (pretending that the estimated scores are the ground trougth)\n",
        "\n",
        "Normally we would need human-labelled data but we pretend it's ok here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRWklR2j__yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first, check the distribution of scores\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AExeFruW__y2",
        "colab_type": "code",
        "outputId": "2f2e4dcd-e077-4b36-f3a8-b75345fe653d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "sns.distplot(english_reviews['score'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01ea202860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAESCAYAAAAPEjVtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6P0yoyT__y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can now say that everything over 0 is positive (which is a bad assumption...but ok)\n",
        "\n",
        "english_reviews['positive'] = english_reviews['score'] >= -.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6L2ddCM__y6",
        "colab_type": "code",
        "outputId": "577fb3cb-5737-4662-b703-4b43a2cbde60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "english_reviews[english_reviews['score'] <= -.5]['comments']"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102580    The host did make me feel welcome, but the pla...\n",
              "289781    As soon as I booked this apartment, I receive ...\n",
              "302167    I reserved Martha's room a week in advance, an...\n",
              "205094    Do not expect parking. My mistake was not cons...\n",
              "237118    Not very clean. Dust and cobwebs everywhere. T...\n",
              "207144    Joseph is a very nice and friendly person over...\n",
              "277830    There was no storage space at all - neither in...\n",
              "78929     Plus for this apartment are good beds, hot wat...\n",
              "37022     \\r\\nEnviado: viernes, 4 de diciembre de 2015 1...\n",
              "329719    We really wanted to leave a better review, but...\n",
              "115560    The proprietor has a lot more work to do here....\n",
              "238734    Nice place, but Marco took advantage of us. Up...\n",
              "140959                                      a very bad host\n",
              "83226     Despite the great location and safe building, ...\n",
              "223557    I have stayed for 10 nights at this Studio. Th...\n",
              "200986    Good location, basic but sufficient apartment....\n",
              "39856     We sadly had a cancelled flight and could not ...\n",
              "275952    I would't have booked the appartment, when the...\n",
              "349945    great place great location. but, i froze to de...\n",
              "210000    BEWARE!!!!! DO NOT TRUST THIS HOSTESS!!!!¬†¬†Sto...\n",
              "200034    ** TERRIBLE ** DO NOT BOOK THIS PLACE. ** DEAT...\n",
              "180847    Host were super, the house wasn't clean at all...\n",
              "240941    The bottom floor flooded after a five minute r...\n",
              "37794     We reserved for 5 people but the flat was set ...\n",
              "202974    This place was not some where someone would wn...\n",
              "155381    The apartment is smaller than expected, but ha...\n",
              "350655    I was contacted by the host through (Hidden by...\n",
              "21855     Rebeca was very easy to work with and get chec...\n",
              "7510      needs a deep clean, we have stayed in a bunch ...\n",
              "135422    I was extremely disappointed by the host. I re...\n",
              "                                ...                        \n",
              "26191     We chose this bnb for a total of 6 nights beca...\n",
              "217838    Muy recomendable \\nSin duda mi lugar en CDMX. ...\n",
              "211031    Affordable and stylish. Only negative about th...\n",
              "63151     The apartment is great but not in top shape. B...\n",
              "242447    It would be good for a weekend but I would not...\n",
              "315829                                       This is a scam\n",
              "351064                        No bad experiences whatsoever\n",
              "41861     Al and Jackie were available for any questions...\n",
              "111967    Needed to wait over 15 minutes to get an answe...\n",
              "249114    Location is good but the apartment could have ...\n",
              "309350    Terrible experience \\nHost failed to communica...\n",
              "89844     Check in was easy, and the host was easy to co...\n",
              "138233    I booked 1 day at Graciela's place and it was ...\n",
              "136415    Very clean apartment in a quiet neighborhood. ...\n",
              "358863    I was very disapointed about feedback from the...\n",
              "30068     Even though the communication with Scott was s...\n",
              "95648     Location was great but host does not really ca...\n",
              "174153    The location and host are deceiving. It's very...\n",
              "276726    For the price, Yulia's room is simply just oka...\n",
              "35320     This place is in the heart of the city, so jus...\n",
              "263079    The airbnb is very clean and it‚Äôs located near...\n",
              "53349                                 Nothing but the best!\n",
              "228331    The place is conveniently located near the Rev...\n",
              "4613      Jeppe's place is central and close to a metro ...\n",
              "229800    This place is not recommendable at all.\\nEntra...\n",
              "71879     No complaints -- Veronica was a very accessibl...\n",
              "220250    The room is located in the old city, around th...\n",
              "269674    One person could take a shower with about 3 mi...\n",
              "294574    DISAPPOINTING. Lacking in basic amenities such...\n",
              "76477     It was the only bad experience I¬¥ve had in Air...\n",
              "Name: comments, Length: 132, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd16QCJl__y_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The most simple way to represent text is by using a so called **bag-of-words** approach. Here we simply count up words in phrases to represent and build a table of phrases (rows) and words (columns)\n",
        "\n",
        "![bow](https://raw.githubusercontent.com/DanAnastasyev/DeepNLP-Course/master/Week%2001/Images/BOW.png)\n",
        "\n",
        "In python we can do something like that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-6T-Yes__y_",
        "colab_type": "code",
        "outputId": "1fe76303-e305-4aa7-b3c9-e9373ca4d866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# Creating a bag of words model\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "dummy_data = ['it was a great experience',\n",
        "              'it was a bad experience']\n",
        "\n",
        "dummy_matrix = vectorizer.fit_transform(dummy_data)\n",
        "\n",
        "\n",
        "pd.DataFrame(data = dummy_matrix.toarray(), columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bad</th>\n",
              "      <th>experience</th>\n",
              "      <th>great</th>\n",
              "      <th>it</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bad  experience  great  it  was\n",
              "0    0           1      1   1    1\n",
              "1    1           1      0   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Kat5OZ__zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will apply this approach to our reviews. But before that we will split up the sample into a training set and a test-set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(english_reviews, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVUnnKq5__zD",
        "colab_type": "code",
        "outputId": "f679cb01-8fb0-4081-80c5-5420226c2a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "dummy_labels = [1, 0]\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(dummy_data, dummy_labels)\n",
        "\n",
        "\n",
        "pd.DataFrame(data = classifier.coef_, columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bad</th>\n",
              "      <th>experience</th>\n",
              "      <th>great</th>\n",
              "      <th>it</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.401058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.401058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        bad  experience     great   it  was\n",
              "0 -0.401058         0.0  0.401058  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64kAkIoM__zH",
        "colab_type": "code",
        "outputId": "06972546-5167-40bb-879d-46d66778a0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "# Let's run a regression on our reviews using the \"positive\" column as a dependant\n",
        "\n",
        "model.fit(train['comments'], train['positive'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='warn', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='warn', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8xEFsJc__zJ",
        "colab_type": "code",
        "outputId": "0b7aff2a-5aae-4894-ec8d-e51409fab586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we can also evaluate the performance\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def eval_model(model, test_df):\n",
        "    preds = model.predict(test['comments'])\n",
        "    print('Test accuracy = {:.2%}'.format(accuracy_score(test['positive'], preds)))\n",
        "    \n",
        "eval_model(model, test)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy = 99.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzvUDp3o__zN",
        "colab_type": "code",
        "outputId": "af565bc8-48fa-4830-dfc5-6bf61e1cd8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Does it really work?\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(test['comments'])\n",
        "y_true = test['positive']\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.47      0.26      0.33        27\n",
            "        True       1.00      1.00      1.00      4973\n",
            "\n",
            "    accuracy                           0.99      5000\n",
            "   macro avg       0.73      0.63      0.67      5000\n",
            "weighted avg       0.99      0.99      0.99      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpppQX-___zR",
        "colab_type": "code",
        "outputId": "9a371eb3-e903-417d-c72e-c07406ae8f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "source": [
        "# How about individual predictions?\n",
        "# We can import the eli5 library that helps us visualising the trained models and results\n",
        "\n",
        "import eli5\n",
        "eli5.show_weights(classifier, vec=vectorizer, top=30)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=True\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.235\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.93%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.590\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        great\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.47%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.254\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        nice\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.40%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.063\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        perfect\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.64%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.015\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        good\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.953\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        beautiful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.04%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.938\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        space\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.64%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.824\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        comfortable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.724\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        location\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.19%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 14177 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.24%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 2762 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.24%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.715\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        walls\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.22%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.718\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        short\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.15%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.732\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        emergency\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.13%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.735\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        terrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.750\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wifi\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.90%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.776\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointed\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.790\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        failed\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.78%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.798\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        street\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.48%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.853\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        refund\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.46%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.858\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        hard\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.34%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.880\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        resolution\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.914\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        lack\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.03%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.939\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        not\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.03%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.940\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wasn\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.953\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        scam\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.55%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.033\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        money\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.04%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.136\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        no\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 91.67%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.212\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        uncomfortable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 91.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.285\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        dirty\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 91.02%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.348\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        nothing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.72%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.869\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        bad\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz3QYZAG__zV",
        "colab_type": "code",
        "outputId": "cb511f4d-cbc8-4937-b7a6-8f7162d79066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Let's check some outcomes\n",
        "\n",
        "print('Positive' if test['positive'].iloc[1] else 'Negative')\n",
        "\n",
        "eli5.show_prediction(classifier, test['comments'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.999</b>, score <b>7.433</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.235\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.57%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.199\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 93.66%); opacity: 0.81\" title=\"-0.114\">marco</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.88%); opacity: 0.81\" title=\"0.109\">is</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 94.73%); opacity: 0.81\" title=\"0.088\">prompt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.97%); opacity: 0.82\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.56%); opacity: 0.85\" title=\"0.408\">helpful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.63%); opacity: 0.82\" title=\"-0.142\">host</span><span style=\"opacity: 0.80\">- </span><span style=\"background-color: hsl(0, 100.00%, 93.60%); opacity: 0.81\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.35%); opacity: 0.92\" title=\"0.938\">space</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.88%); opacity: 0.81\" title=\"0.109\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.59%); opacity: 0.83\" title=\"0.232\">super</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.14%); opacity: 0.85\" title=\"0.386\">cute</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 89.75%); opacity: 0.83\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.590\">great</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.94%); opacity: 0.89\" title=\"0.724\">location</span><span style=\"opacity: 0.80\">- </span><span style=\"background-color: hsl(0, 100.00%, 90.87%); opacity: 0.82\" title=\"-0.193\">it</span><span style=\"opacity: 0.80\">‚Äôs a </span><span style=\"background-color: hsl(120, 100.00%, 78.45%); opacity: 0.88\" title=\"0.657\">bit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.16%); opacity: 0.81\" title=\"-0.078\">loud</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.32%); opacity: 0.86\" title=\"-0.456\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.36%); opacity: 0.97\" title=\"-1.348\">nothing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.34%); opacity: 0.80\" title=\"0.017\">crazy</span><span style=\"opacity: 0.80\">!</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkv60D-1__zX",
        "colab_type": "code",
        "outputId": "2331f2ef-a07f-4082-f0d7-77f008ecd0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "# Let's look at the worst reviews\n",
        "test[test.positive == 0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>listing_id</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>reviewer_id</th>\n",
              "      <th>reviewer_name</th>\n",
              "      <th>comments</th>\n",
              "      <th>lang</th>\n",
              "      <th>score</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>362108</th>\n",
              "      <td>32317521</td>\n",
              "      <td>444278196</td>\n",
              "      <td>2019-04-27</td>\n",
              "      <td>220285322</td>\n",
              "      <td>Lizet</td>\n",
              "      <td>It really is close to the airport, just keep i...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6905</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268129</th>\n",
              "      <td>22320739</td>\n",
              "      <td>318804135</td>\n",
              "      <td>2018-09-04</td>\n",
              "      <td>120091818</td>\n",
              "      <td>Eddie</td>\n",
              "      <td>You probably don't know, but Jesus never exist...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.8957</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135422</th>\n",
              "      <td>14320958</td>\n",
              "      <td>406997251</td>\n",
              "      <td>2019-01-31</td>\n",
              "      <td>28555378</td>\n",
              "      <td>Rob</td>\n",
              "      <td>I was extremely disappointed by the host. I re...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9227</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228331</th>\n",
              "      <td>19999614</td>\n",
              "      <td>364910193</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>57454161</td>\n",
              "      <td>Serdar</td>\n",
              "      <td>The place is conveniently located near the Rev...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.5647</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269674</th>\n",
              "      <td>22387495</td>\n",
              "      <td>349493513</td>\n",
              "      <td>2018-11-17</td>\n",
              "      <td>8936300</td>\n",
              "      <td>Ronnie</td>\n",
              "      <td>One person could take a shower with about 3 mi...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9397</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228464</th>\n",
              "      <td>20014539</td>\n",
              "      <td>320315442</td>\n",
              "      <td>2018-09-08</td>\n",
              "      <td>19157029</td>\n",
              "      <td>Robin</td>\n",
              "      <td>My husband and I were very excited to stay her...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9557</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7510</th>\n",
              "      <td>796477</td>\n",
              "      <td>362557039</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>73038592</td>\n",
              "      <td>Elise</td>\n",
              "      <td>needs a deep clean, we have stayed in a bunch ...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.8418</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349945</th>\n",
              "      <td>29970560</td>\n",
              "      <td>401696158</td>\n",
              "      <td>2019-01-15</td>\n",
              "      <td>4285112</td>\n",
              "      <td>Aziz</td>\n",
              "      <td>great place great location. but, i froze to de...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6530</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78929</th>\n",
              "      <td>9411939</td>\n",
              "      <td>422644539</td>\n",
              "      <td>2019-03-11</td>\n",
              "      <td>528720</td>\n",
              "      <td>Susan Simone</td>\n",
              "      <td>Plus for this apartment are good beds, hot wat...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.8807</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4613</th>\n",
              "      <td>480752</td>\n",
              "      <td>171779290</td>\n",
              "      <td>2017-07-18</td>\n",
              "      <td>6761119</td>\n",
              "      <td>Harlen</td>\n",
              "      <td>Jeppe's place is central and close to a metro ...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6879</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115621</th>\n",
              "      <td>12951673</td>\n",
              "      <td>183953513</td>\n",
              "      <td>2017-08-18</td>\n",
              "      <td>2809864</td>\n",
              "      <td>Tessa</td>\n",
              "      <td>Apartment was not cleaned after the guests bef...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.8306</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200986</th>\n",
              "      <td>18405139</td>\n",
              "      <td>402500282</td>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>137146396</td>\n",
              "      <td>Safia</td>\n",
              "      <td>Good location, basic but sufficient apartment....</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9688</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174153</th>\n",
              "      <td>16909747</td>\n",
              "      <td>222409139</td>\n",
              "      <td>2017-12-29</td>\n",
              "      <td>8883004</td>\n",
              "      <td>Jean</td>\n",
              "      <td>The location and host are deceiving. It's very...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9118</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226967</th>\n",
              "      <td>19944338</td>\n",
              "      <td>264742205</td>\n",
              "      <td>2018-05-14</td>\n",
              "      <td>141979258</td>\n",
              "      <td>Norbert</td>\n",
              "      <td>Sehr gute Lage.\\nDie unterkunft ist klein, abe...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.5994</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258119</th>\n",
              "      <td>21812920</td>\n",
              "      <td>423246653</td>\n",
              "      <td>2019-03-13</td>\n",
              "      <td>71763703</td>\n",
              "      <td>Beiyan</td>\n",
              "      <td>A small but full-equipped flat. The building i...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.8129</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76477</th>\n",
              "      <td>9186698</td>\n",
              "      <td>68238891</td>\n",
              "      <td>2016-04-03</td>\n",
              "      <td>3114278</td>\n",
              "      <td>Quetzalli</td>\n",
              "      <td>It was the only bad experience I¬¥ve had in Air...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.7302</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111967</th>\n",
              "      <td>12726023</td>\n",
              "      <td>368982146</td>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>149835443</td>\n",
              "      <td>Pedro</td>\n",
              "      <td>Needed to wait over 15 minutes to get an answe...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6597</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350655</th>\n",
              "      <td>30049209</td>\n",
              "      <td>454579695</td>\n",
              "      <td>2019-05-18</td>\n",
              "      <td>196710916</td>\n",
              "      <td>Gregory</td>\n",
              "      <td>I was contacted by the host through (Hidden by...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9441</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89844</th>\n",
              "      <td>10350201</td>\n",
              "      <td>222074463</td>\n",
              "      <td>2017-12-28</td>\n",
              "      <td>677632</td>\n",
              "      <td>Kyle</td>\n",
              "      <td>Check in was easy, and the host was easy to co...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6772</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42690</th>\n",
              "      <td>5345394</td>\n",
              "      <td>49116429</td>\n",
              "      <td>2015-10-01</td>\n",
              "      <td>14671569</td>\n",
              "      <td>Jeremy</td>\n",
              "      <td>This unit had some problems with the plumbing....</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9071</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10314</th>\n",
              "      <td>1074844</td>\n",
              "      <td>446099915</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>105154030</td>\n",
              "      <td>Scarlett</td>\n",
              "      <td>Bed bugs !! And Airbnb sucks because no one to...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6467</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340826</th>\n",
              "      <td>28662198</td>\n",
              "      <td>349475918</td>\n",
              "      <td>2018-11-17</td>\n",
              "      <td>11315565</td>\n",
              "      <td>Nika</td>\n",
              "      <td>Pros: accesible and safe neighbourhood, parkin...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9145</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319009</th>\n",
              "      <td>26181486</td>\n",
              "      <td>443758174</td>\n",
              "      <td>2019-04-26</td>\n",
              "      <td>124494222</td>\n",
              "      <td>Samantha</td>\n",
              "      <td>Decent place. Had a mishap with the water heat...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6808</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102580</th>\n",
              "      <td>11702309</td>\n",
              "      <td>88833959</td>\n",
              "      <td>2016-07-25</td>\n",
              "      <td>61273617</td>\n",
              "      <td>Gabi</td>\n",
              "      <td>The host did make me feel welcome, but the pla...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.9410</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37794</th>\n",
              "      <td>4933231</td>\n",
              "      <td>133752607</td>\n",
              "      <td>2017-02-24</td>\n",
              "      <td>49364228</td>\n",
              "      <td>Gabriela And Didier</td>\n",
              "      <td>We reserved for 5 people but the flat was set ...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.7445</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214283</th>\n",
              "      <td>19196391</td>\n",
              "      <td>299313208</td>\n",
              "      <td>2018-07-30</td>\n",
              "      <td>1689228</td>\n",
              "      <td>Rob</td>\n",
              "      <td>Incredible view and very close to Zocalo. Wate...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.7178</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195169</th>\n",
              "      <td>18093250</td>\n",
              "      <td>351974527</td>\n",
              "      <td>2018-11-24</td>\n",
              "      <td>2510516</td>\n",
              "      <td>Justin</td>\n",
              "      <td>We unfortunately experienced issues with loud ...</td>\n",
              "      <td>en</td>\n",
              "      <td>-0.6685</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        listing_id         id        date  ...  lang   score positive\n",
              "362108    32317521  444278196  2019-04-27  ...    en -0.6905    False\n",
              "268129    22320739  318804135  2018-09-04  ...    en -0.8957    False\n",
              "135422    14320958  406997251  2019-01-31  ...    en -0.9227    False\n",
              "228331    19999614  364910193  2018-12-31  ...    en -0.5647    False\n",
              "269674    22387495  349493513  2018-11-17  ...    en -0.9397    False\n",
              "228464    20014539  320315442  2018-09-08  ...    en -0.9557    False\n",
              "7510        796477  362557039  2018-12-26  ...    en -0.8418    False\n",
              "349945    29970560  401696158  2019-01-15  ...    en -0.6530    False\n",
              "78929      9411939  422644539  2019-03-11  ...    en -0.8807    False\n",
              "4613        480752  171779290  2017-07-18  ...    en -0.6879    False\n",
              "115621    12951673  183953513  2017-08-18  ...    en -0.8306    False\n",
              "200986    18405139  402500282  2019-01-18  ...    en -0.9688    False\n",
              "174153    16909747  222409139  2017-12-29  ...    en -0.9118    False\n",
              "226967    19944338  264742205  2018-05-14  ...    en -0.5994    False\n",
              "258119    21812920  423246653  2019-03-13  ...    en -0.8129    False\n",
              "76477      9186698   68238891  2016-04-03  ...    en -0.7302    False\n",
              "111967    12726023  368982146  2019-01-08  ...    en -0.6597    False\n",
              "350655    30049209  454579695  2019-05-18  ...    en -0.9441    False\n",
              "89844     10350201  222074463  2017-12-28  ...    en -0.6772    False\n",
              "42690      5345394   49116429  2015-10-01  ...    en -0.9071    False\n",
              "10314      1074844  446099915  2019-04-30  ...    en -0.6467    False\n",
              "340826    28662198  349475918  2018-11-17  ...    en -0.9145    False\n",
              "319009    26181486  443758174  2019-04-26  ...    en -0.6808    False\n",
              "102580    11702309   88833959  2016-07-25  ...    en -0.9410    False\n",
              "37794      4933231  133752607  2017-02-24  ...    en -0.7445    False\n",
              "214283    19196391  299313208  2018-07-30  ...    en -0.7178    False\n",
              "195169    18093250  351974527  2018-11-24  ...    en -0.6685    False\n",
              "\n",
              "[27 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWb14CCD__zZ",
        "colab_type": "code",
        "outputId": "2e3d5dc9-cef9-42e5-c435-7ef5959b6736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "print('Positive' if test[test.positive == 0]['positive'].iloc[2] else 'Negative')\n",
        "\n",
        "eli5.show_prediction(classifier, test[test.positive == 0]['comments'].iloc[2], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.589</b>, score <b>0.359</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.235\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.20%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.876\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"opacity: 0.80\">i </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.27%); opacity: 0.81\" title=\"0.071\">extremely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.37%); opacity: 0.94\" title=\"-0.776\">disappointed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.164\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.68%); opacity: 0.82\" title=\"-0.142\">host</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.128\">received</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 96.54%); opacity: 0.81\" title=\"-0.034\">text</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.446\">as</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.92%); opacity: 0.80\" title=\"0.007\">landing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.09%); opacity: 0.83\" title=\"0.155\">mexico</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.77%); opacity: 0.84\" title=\"0.209\">city</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.26%); opacity: 0.80\" title=\"-0.025\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.78%); opacity: 0.86\" title=\"0.313\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.60%); opacity: 0.83\" title=\"0.166\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> 4 </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.00%); opacity: 0.97\" title=\"-0.939\">not</span><span style=\"opacity: 0.80\"> 3 </span><span style=\"background-color: hsl(120, 100.00%, 94.51%); opacity: 0.81\" title=\"0.067\">pm</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.65%); opacity: 0.81\" title=\"0.082\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.136\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.96%); opacity: 0.83\" title=\"0.181\">early</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.78%); opacity: 0.86\" title=\"0.313\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.67%); opacity: 0.85\" title=\"0.262\">allowed</span><span style=\"opacity: 0.80\">( </span><span style=\"background-color: hsl(120, 100.00%, 96.14%); opacity: 0.81\" title=\"0.040\">sent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.35%); opacity: 0.82\" title=\"-0.127\">her</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 96.54%); opacity: 0.81\" title=\"-0.034\">text</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.26%); opacity: 0.81\" title=\"-0.071\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.49%); opacity: 0.88\" title=\"0.438\">before</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.78%); opacity: 0.81\" title=\"-0.031\">asking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.25%); opacity: 0.88\" title=\"0.445\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.90%); opacity: 0.82\" title=\"-0.116\">ok</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.83%); opacity: 0.84\" title=\"-0.208\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.78%); opacity: 0.86\" title=\"0.313\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.23%); opacity: 0.82\" title=\"0.130\">at</span><span style=\"opacity: 0.80\"> 3 </span><span style=\"background-color: hsl(120, 100.00%, 94.51%); opacity: 0.81\" title=\"0.067\">pm</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.04%); opacity: 0.84\" title=\"-0.253\">got</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.136\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.12%); opacity: 0.82\" title=\"0.132\">response</span><span style=\"opacity: 0.80\"> )\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.68%); opacity: 0.82\" title=\"-0.142\">host</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 90.49%); opacity: 0.83\" title=\"-0.146\">showed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.11%); opacity: 0.83\" title=\"0.177\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.23%); opacity: 0.82\" title=\"0.130\">at</span><span style=\"opacity: 0.80\"> 4:</span><span style=\"background-color: hsl(120, 100.00%, 94.78%); opacity: 0.81\" title=\"0.062\">25</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.51%); opacity: 0.81\" title=\"0.067\">pm</span><span style=\"opacity: 0.80\">!  </span><span style=\"background-color: hsl(120, 100.00%, 96.48%); opacity: 0.81\" title=\"0.035\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.39%); opacity: 0.80\" title=\"0.003\">very</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.053\">late</span><span style=\"opacity: 0.80\"> !\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.68%); opacity: 0.82\" title=\"-0.142\">host</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.30%); opacity: 0.80\" title=\"-0.024\">chose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.00%); opacity: 0.97\" title=\"-0.939\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.83%); opacity: 0.84\" title=\"-0.208\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.48%); opacity: 0.89\" title=\"-0.500\">tell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.68%); opacity: 0.84\" title=\"0.236\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.26%); opacity: 0.80\" title=\"-0.025\">that</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 99.68%); opacity: 0.80\" title=\"0.001\">tremendous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.164\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.056\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.21%); opacity: 0.83\" title=\"-0.152\">noise</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.97%); opacity: 0.82\" title=\"-0.095\">dust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.84%); opacity: 0.82\" title=\"0.097\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.056\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.94%); opacity: 0.81\" title=\"0.043\">construction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.07%); opacity: 0.91\" title=\"-0.612\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.65%); opacity: 0.81\" title=\"0.082\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.82%); opacity: 0.80\" title=\"-0.007\">bottom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.73%); opacity: 0.89\" title=\"-0.524\">floor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.056\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.36%); opacity: 0.86\" title=\"0.353\">building</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(0, 100.00%, 91.93%); opacity: 0.82\" title=\"-0.116\">unit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.26%); opacity: 0.82\" title=\"0.109\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.21%); opacity: 0.89\" title=\"0.509\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.73%); opacity: 0.89\" title=\"-0.524\">floor</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.446\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.01%); opacity: 0.90\" title=\"0.580\">well</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.446\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.00%); opacity: 0.81\" title=\"0.076\">coming</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.21%); opacity: 0.80\" title=\"0.013\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.60%); opacity: 0.82\" title=\"0.102\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.01%); opacity: 0.86\" title=\"0.363\">apartment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.64%); opacity: 0.83\" title=\"0.143\">complex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.74%); opacity: 0.87\" title=\"-0.371\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.89%); opacity: 0.80\" title=\"0.007\">remodeled</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.93%); opacity: 0.90\" title=\"-0.550\">across</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.76%); opacity: 0.94\" title=\"-0.798\">street</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(120, 100.00%, 89.28%); opacity: 0.83\" title=\"0.173\">we</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.77%); opacity: 0.86\" title=\"-0.341\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.93%); opacity: 0.80\" title=\"0.006\">awake</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.56%); opacity: 0.85\" title=\"0.265\">every</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.26%); opacity: 0.81\" title=\"-0.071\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.09%); opacity: 0.81\" title=\"0.074\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 100.00%); opacity: 0.80\" title=\"0.000\">pounding</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.21%); opacity: 0.83\" title=\"-0.152\">noise</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.98%); opacity: 0.80\" title=\"0.000\">drill</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 99.35%); opacity: 0.80\" title=\"0.003\">electric</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.34%); opacity: 0.82\" title=\"0.107\">saw</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.446\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.96%); opacity: 0.83\" title=\"0.181\">early</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.446\">as</span><span style=\"opacity: 0.80\"> 8 </span><span style=\"background-color: hsl(0, 100.00%, 90.21%); opacity: 0.83\" title=\"-0.152\">til</span><span style=\"opacity: 0.80\"> 7 </span><span style=\"background-color: hsl(120, 100.00%, 94.51%); opacity: 0.81\" title=\"0.067\">pm</span><span style=\"opacity: 0.80\"> \n",
              "i </span><span style=\"background-color: hsl(120, 100.00%, 92.43%); opacity: 0.82\" title=\"0.105\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.00%); opacity: 0.97\" title=\"-0.939\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.60%); opacity: 0.82\" title=\"-0.102\">make</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.58%); opacity: 0.83\" title=\"-0.189\">any</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.47%); opacity: 0.81\" title=\"0.035\">call</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.21%); opacity: 0.80\" title=\"0.013\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.01%); opacity: 0.86\" title=\"0.363\">apartment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.84%); opacity: 0.82\" title=\"0.097\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.056\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.51%); opacity: 0.93\" title=\"-0.735\">terrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.21%); opacity: 0.83\" title=\"-0.152\">noise</span><span style=\"opacity: 0.80\"> .a </span><span style=\"background-color: hsl(0, 100.00%, 95.36%); opacity: 0.81\" title=\"-0.052\">total</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.37%); opacity: 0.80\" title=\"0.003\">nite</span><span style=\"opacity: 0.80\"> mare ! </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.136\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.39%); opacity: 0.81\" title=\"0.052\">nap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.136\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.10%); opacity: 0.82\" title=\"-0.133\">sleeping</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.053\">late</span><span style=\"opacity: 0.80\"> ! </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.116\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.01%); opacity: 0.86\" title=\"0.363\">apartment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.26%); opacity: 0.82\" title=\"0.109\">is</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 72.74%); opacity: 0.92\" title=\"0.657\">bit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.015\">run</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.02%); opacity: 0.83\" title=\"0.179\">down</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.84%); opacity: 0.83\" title=\"0.160\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.68%); opacity: 0.87\" title=\"0.372\">need</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.96%); opacity: 0.82\" title=\"-0.136\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.93%); opacity: 0.81\" title=\"-0.029\">major</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.96%); opacity: 0.81\" title=\"-0.029\">update</span><span style=\"opacity: 0.80\"> ! i </span><span style=\"background-color: hsl(120, 100.00%, 85.94%); opacity: 0.84\" title=\"0.255\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.00%); opacity: 0.97\" title=\"-0.939\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.09%); opacity: 0.90\" title=\"0.578\">recommend</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.26%); opacity: 0.80\" title=\"-0.025\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.41%); opacity: 0.83\" title=\"0.170\">home</span><span style=\"opacity: 0.80\"> !</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t4JhXj5__zc",
        "colab_type": "text"
      },
      "source": [
        "## Short intro to Word Vectors\n",
        "\n",
        "![](http://ruder.io/content/images/size/w1000/2017/10/semantic_change.png)\n",
        "\n",
        "Word embeddings became big around 2013 and are linked to [this paper](https://arxiv.org/abs/1301.3781) with the beautiful title \n",
        "*Efficient Estimation of Word Representations in Vector Space* by Tomas Mokolov et al. coming out of Google. This was the foundation of Word2Vec.\n",
        "\n",
        "The idea behind it is easiest summarized by the following quote: \n",
        "\n",
        "\n",
        "> *You shall know a word by the company it keeps (Firth, J. R. 1957:11)*\n",
        "\n",
        "Let me start with a fascinating example of word embeddings in practice. Below, you can see a figure from the paper: \n",
        "*Dynamic Word Embeddings for Evolving Semantic Discovery*. Here (in simple terms) the researchers estimated word vectors for from textual inputs in different time-frames. They picked out some terms and person that obviously changed *their company* over the years. Then they look at the relative position of these terms compared to terms that did not change much (anchors). If you are interested in this kind of research, check out [this blog](https://blog.acolyer.org/2018/02/22/dynamic-word-embeddings-for-evolving-semantic-discovery/) that describes the paper briefly or the [original paper](https://arxiv.org/abs/1703.00607).\n",
        "\n",
        "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/06062705/Word-Vectors.png)\n",
        "\n",
        "Word embeddings allow us to create term representations that \"learn\" meaning from semantic and syntactic features. These models take a sequence of sentences as an input and scan for all individual terms that appear in the whole corpus and all their occurrences. Such contextual learning seems to be able to pick up non-trivial conceptual details and it is this class of models that today enable technologies such as chatbots, machine translation and much more.\n",
        "\n",
        "The early word embedding models were Word2Vec and [GloVe](https://nlp.stanford.edu/projects/glove/).\n",
        "In December 2017 Facebook presented [fastText](https://fasttext.cc/) (by the way - by 2017 Tomas Mikolov was working for Facebook and is one of the authors of the [paper](https://arxiv.org/abs/1607.04606) that introduces the research behind fastText). This model extends the idea of Word2Vec, enriching these vectors by information from sub-word elements. What does that mean? Words are not only defined by surrounding words but in addition also by the various syllables that make up the word. Why should that be a good idea? Well, now words such as *apple* and *apples* do not only get similar vectors due to them often sharing context but also because they are composed of the same sub-word elements. This comes in particularly handy when we are dealing with language that have a rich morphology such as Turkish or Russian.  This is also great when working with web-text, which is often messy and misspelt.\n",
        "\n",
        "The current state-of-the-art (April 2018!) is ELMo (Embeddings from Language Models) that further tackles the problem of contextuality and particularly polysemy, i.e. same term means something else in a different context. \n",
        "\n",
        "You can read more about the ins and outs of the current state of embedding models [here](https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a).\n",
        "\n",
        "Now the good news: You will find pre-trained vectors from all mentioned models online. They will do great in most cases. However, when working with specific tasks: Some obscure languages and/or specific technical jargon (finance talk), it is nice to know how to train such word-vectors.\n",
        "\n",
        "In this tutorial and on M3 we will not go further than fastText (2017-state-of-the-art should be good enough for us ‚Äì sorry). You are more than welcome to use other, more sophisticated, embeddings.\n",
        "\n",
        "\n",
        "In this tutorial we will train three embedding models:\n",
        "\n",
        "- Word2Vec on text8 - a sample of English Wikipedia\n",
        "- Word2Vec on the hate speech and toxic comments data\n",
        "- fastText on the toxic comments data\n",
        "\n",
        "Once trained, we will store the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXboeud0E7V",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "3962d0a9-00f1-4133-c5c8-acb3ed0501e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "#@title ### One more time\n",
        "variable_name = \"\"\n",
        "\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('xMwx2A_o5r4',start=0, frameborder=\"0\", width=800, height=500)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"500\"\n",
              "            src=\"https://www.youtube.com/embed/xMwx2A_o5r4?start=0&frameborder=0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f01cb651cc0>"
            ],
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nAAAAAAAAAAAAAAAAAAAAAAAAAAB//9k=\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYjcYnik__zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will train a spanish word-model using gensim and based on all english reviews\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVwILZd7__zf",
        "colab_type": "code",
        "outputId": "a16a1ef4-0588-4820-b3ff-9ff9b3d68221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Some tools that we need to prepare our data for training\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJedQ30uVMnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Going back to the full sample\n",
        "english_reviews = reviews[reviews['lang'] == 'en']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyx_PHK-__zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first we create a list of reviews\n",
        "\n",
        "texts = list(english_reviews.comments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWg-AytH__zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we split the reviews up in sentences\n",
        "\n",
        "sents = []\n",
        "for text in texts:\n",
        "  sents.extend(sent_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28b8GbFR__z1",
        "colab_type": "code",
        "outputId": "afee964f-a682-454e-c33c-548daf8e37cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# how many?\n",
        "\n",
        "len(sents)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "772819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msdV6raa__z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we create tokenized sentenses - sentences will be now lists of individual words (or tokens)\n",
        "\n",
        "tokenized_texts = [word_tokenize(text) for text in sents]\n",
        "tokenized_texts = list(map(lambda x: [y.lower() for y in x], tokenized_texts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShF_ati-__z4",
        "colab_type": "code",
        "outputId": "176395b9-750b-40c2-9236-19ed98a06292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# now we have created a container with word-sequences\n",
        "tokenized_texts[:5]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'loved', 'the', 'experience', '.'],\n",
              " ['paige',\n",
              "  'was',\n",
              "  'super',\n",
              "  'knowledgeable',\n",
              "  'about',\n",
              "  'craft',\n",
              "  'beer',\n",
              "  'and',\n",
              "  'brought',\n",
              "  'us',\n",
              "  'to',\n",
              "  'some',\n",
              "  'great',\n",
              "  'places',\n",
              "  'in',\n",
              "  'vancouver',\n",
              "  '.'],\n",
              " ['highly',\n",
              "  'recommended',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'wanting',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'more',\n",
              "  'about',\n",
              "  'beer',\n",
              "  'and',\n",
              "  'try',\n",
              "  'some',\n",
              "  'great',\n",
              "  'local',\n",
              "  'breweries'],\n",
              " ['paige',\n",
              "  'was',\n",
              "  'the',\n",
              "  'perfect',\n",
              "  'host',\n",
              "  'and',\n",
              "  'passed',\n",
              "  'on',\n",
              "  'her',\n",
              "  'wealth',\n",
              "  'of',\n",
              "  'knowledge',\n",
              "  'of',\n",
              "  'craft',\n",
              "  'beers',\n",
              "  'and',\n",
              "  'the',\n",
              "  'whereabouts',\n",
              "  'of',\n",
              "  'which',\n",
              "  'we',\n",
              "  'would',\n",
              "  'have',\n",
              "  'not',\n",
              "  'been',\n",
              "  'able',\n",
              "  'to',\n",
              "  'find',\n",
              "  'without',\n",
              "  'her',\n",
              "  'in-depth',\n",
              "  'local',\n",
              "  'knowledge',\n",
              "  '.'],\n",
              " ['we', 'had', 'a', 'great', 'time', '!']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXOCjo7k__z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We import logging to get informative outputs from Gensim training\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLOtm80__z_",
        "colab_type": "code",
        "outputId": "141d380f-ab66-41f8-cdda-5915006a0a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# this is how we train the model\n",
        "\n",
        "model = Word2Vec(tokenized_texts, \n",
        "                 size=64,      # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 10 times\n",
        "                 window=8\n",
        "                ).wv  # define context as a 5-word window around the target word"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-12 10:22:13,720 : INFO : collecting all words and their counts\n",
            "2019-08-12 10:22:13,723 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-08-12 10:22:13,770 : INFO : PROGRESS: at sentence #10000, processed 156597 words, keeping 6518 word types\n",
            "2019-08-12 10:22:13,810 : INFO : PROGRESS: at sentence #20000, processed 306416 words, keeping 9394 word types\n",
            "2019-08-12 10:22:13,850 : INFO : PROGRESS: at sentence #30000, processed 456602 words, keeping 11687 word types\n",
            "2019-08-12 10:22:13,889 : INFO : PROGRESS: at sentence #40000, processed 607544 words, keeping 13526 word types\n",
            "2019-08-12 10:22:13,928 : INFO : PROGRESS: at sentence #50000, processed 756366 words, keeping 14995 word types\n",
            "2019-08-12 10:22:13,969 : INFO : PROGRESS: at sentence #60000, processed 905418 words, keeping 16430 word types\n",
            "2019-08-12 10:22:14,008 : INFO : PROGRESS: at sentence #70000, processed 1052493 words, keeping 17708 word types\n",
            "2019-08-12 10:22:14,048 : INFO : PROGRESS: at sentence #80000, processed 1201845 words, keeping 18916 word types\n",
            "2019-08-12 10:22:14,087 : INFO : PROGRESS: at sentence #90000, processed 1350783 words, keeping 20165 word types\n",
            "2019-08-12 10:22:14,126 : INFO : PROGRESS: at sentence #100000, processed 1497144 words, keeping 21426 word types\n",
            "2019-08-12 10:22:14,166 : INFO : PROGRESS: at sentence #110000, processed 1643450 words, keeping 22411 word types\n",
            "2019-08-12 10:22:14,207 : INFO : PROGRESS: at sentence #120000, processed 1788760 words, keeping 23488 word types\n",
            "2019-08-12 10:22:14,249 : INFO : PROGRESS: at sentence #130000, processed 1933311 words, keeping 24443 word types\n",
            "2019-08-12 10:22:14,290 : INFO : PROGRESS: at sentence #140000, processed 2079139 words, keeping 25475 word types\n",
            "2019-08-12 10:22:14,329 : INFO : PROGRESS: at sentence #150000, processed 2222406 words, keeping 26398 word types\n",
            "2019-08-12 10:22:14,372 : INFO : PROGRESS: at sentence #160000, processed 2368116 words, keeping 27260 word types\n",
            "2019-08-12 10:22:14,411 : INFO : PROGRESS: at sentence #170000, processed 2511940 words, keeping 28052 word types\n",
            "2019-08-12 10:22:14,455 : INFO : PROGRESS: at sentence #180000, processed 2656180 words, keeping 28870 word types\n",
            "2019-08-12 10:22:14,499 : INFO : PROGRESS: at sentence #190000, processed 2800311 words, keeping 29728 word types\n",
            "2019-08-12 10:22:14,543 : INFO : PROGRESS: at sentence #200000, processed 2947463 words, keeping 30605 word types\n",
            "2019-08-12 10:22:14,583 : INFO : PROGRESS: at sentence #210000, processed 3090301 words, keeping 31346 word types\n",
            "2019-08-12 10:22:14,623 : INFO : PROGRESS: at sentence #220000, processed 3233462 words, keeping 32167 word types\n",
            "2019-08-12 10:22:14,665 : INFO : PROGRESS: at sentence #230000, processed 3377860 words, keeping 32818 word types\n",
            "2019-08-12 10:22:14,706 : INFO : PROGRESS: at sentence #240000, processed 3521362 words, keeping 33435 word types\n",
            "2019-08-12 10:22:14,746 : INFO : PROGRESS: at sentence #250000, processed 3663412 words, keeping 34222 word types\n",
            "2019-08-12 10:22:14,786 : INFO : PROGRESS: at sentence #260000, processed 3804069 words, keeping 34913 word types\n",
            "2019-08-12 10:22:14,828 : INFO : PROGRESS: at sentence #270000, processed 3952410 words, keeping 35656 word types\n",
            "2019-08-12 10:22:14,868 : INFO : PROGRESS: at sentence #280000, processed 4089146 words, keeping 36279 word types\n",
            "2019-08-12 10:22:14,909 : INFO : PROGRESS: at sentence #290000, processed 4230829 words, keeping 36891 word types\n",
            "2019-08-12 10:22:14,949 : INFO : PROGRESS: at sentence #300000, processed 4372797 words, keeping 37520 word types\n",
            "2019-08-12 10:22:14,985 : INFO : PROGRESS: at sentence #310000, processed 4514018 words, keeping 38133 word types\n",
            "2019-08-12 10:22:15,024 : INFO : PROGRESS: at sentence #320000, processed 4654046 words, keeping 38803 word types\n",
            "2019-08-12 10:22:15,065 : INFO : PROGRESS: at sentence #330000, processed 4795369 words, keeping 39423 word types\n",
            "2019-08-12 10:22:15,106 : INFO : PROGRESS: at sentence #340000, processed 4932638 words, keeping 40024 word types\n",
            "2019-08-12 10:22:15,150 : INFO : PROGRESS: at sentence #350000, processed 5076365 words, keeping 40592 word types\n",
            "2019-08-12 10:22:15,190 : INFO : PROGRESS: at sentence #360000, processed 5215616 words, keeping 41136 word types\n",
            "2019-08-12 10:22:15,230 : INFO : PROGRESS: at sentence #370000, processed 5353792 words, keeping 41638 word types\n",
            "2019-08-12 10:22:15,269 : INFO : PROGRESS: at sentence #380000, processed 5492319 words, keeping 42195 word types\n",
            "2019-08-12 10:22:15,309 : INFO : PROGRESS: at sentence #390000, processed 5630626 words, keeping 42873 word types\n",
            "2019-08-12 10:22:15,349 : INFO : PROGRESS: at sentence #400000, processed 5770382 words, keeping 43431 word types\n",
            "2019-08-12 10:22:15,389 : INFO : PROGRESS: at sentence #410000, processed 5907765 words, keeping 43923 word types\n",
            "2019-08-12 10:22:15,431 : INFO : PROGRESS: at sentence #420000, processed 6048191 words, keeping 44440 word types\n",
            "2019-08-12 10:22:15,476 : INFO : PROGRESS: at sentence #430000, processed 6187914 words, keeping 44967 word types\n",
            "2019-08-12 10:22:15,515 : INFO : PROGRESS: at sentence #440000, processed 6325731 words, keeping 45594 word types\n",
            "2019-08-12 10:22:15,555 : INFO : PROGRESS: at sentence #450000, processed 6463235 words, keeping 46215 word types\n",
            "2019-08-12 10:22:15,594 : INFO : PROGRESS: at sentence #460000, processed 6599856 words, keeping 46791 word types\n",
            "2019-08-12 10:22:15,634 : INFO : PROGRESS: at sentence #470000, processed 6737187 words, keeping 47368 word types\n",
            "2019-08-12 10:22:15,678 : INFO : PROGRESS: at sentence #480000, processed 6875727 words, keeping 47901 word types\n",
            "2019-08-12 10:22:15,718 : INFO : PROGRESS: at sentence #490000, processed 7014283 words, keeping 48414 word types\n",
            "2019-08-12 10:22:15,761 : INFO : PROGRESS: at sentence #500000, processed 7150695 words, keeping 48939 word types\n",
            "2019-08-12 10:22:15,802 : INFO : PROGRESS: at sentence #510000, processed 7288337 words, keeping 49481 word types\n",
            "2019-08-12 10:22:15,844 : INFO : PROGRESS: at sentence #520000, processed 7425751 words, keeping 49923 word types\n",
            "2019-08-12 10:22:15,887 : INFO : PROGRESS: at sentence #530000, processed 7567844 words, keeping 50453 word types\n",
            "2019-08-12 10:22:15,929 : INFO : PROGRESS: at sentence #540000, processed 7706528 words, keeping 50914 word types\n",
            "2019-08-12 10:22:15,968 : INFO : PROGRESS: at sentence #550000, processed 7841655 words, keeping 51396 word types\n",
            "2019-08-12 10:22:16,007 : INFO : PROGRESS: at sentence #560000, processed 7979075 words, keeping 51949 word types\n",
            "2019-08-12 10:22:16,051 : INFO : PROGRESS: at sentence #570000, processed 8117871 words, keeping 52598 word types\n",
            "2019-08-12 10:22:16,090 : INFO : PROGRESS: at sentence #580000, processed 8254000 words, keeping 53120 word types\n",
            "2019-08-12 10:22:16,129 : INFO : PROGRESS: at sentence #590000, processed 8392009 words, keeping 53550 word types\n",
            "2019-08-12 10:22:16,173 : INFO : PROGRESS: at sentence #600000, processed 8530097 words, keeping 54070 word types\n",
            "2019-08-12 10:22:16,212 : INFO : PROGRESS: at sentence #610000, processed 8665062 words, keeping 54570 word types\n",
            "2019-08-12 10:22:16,254 : INFO : PROGRESS: at sentence #620000, processed 8800037 words, keeping 55003 word types\n",
            "2019-08-12 10:22:16,296 : INFO : PROGRESS: at sentence #630000, processed 8936237 words, keeping 55504 word types\n",
            "2019-08-12 10:22:16,335 : INFO : PROGRESS: at sentence #640000, processed 9072081 words, keeping 55993 word types\n",
            "2019-08-12 10:22:16,375 : INFO : PROGRESS: at sentence #650000, processed 9210831 words, keeping 56543 word types\n",
            "2019-08-12 10:22:16,415 : INFO : PROGRESS: at sentence #660000, processed 9348116 words, keeping 57025 word types\n",
            "2019-08-12 10:22:16,453 : INFO : PROGRESS: at sentence #670000, processed 9482177 words, keeping 57499 word types\n",
            "2019-08-12 10:22:16,494 : INFO : PROGRESS: at sentence #680000, processed 9616033 words, keeping 57998 word types\n",
            "2019-08-12 10:22:16,536 : INFO : PROGRESS: at sentence #690000, processed 9753909 words, keeping 58452 word types\n",
            "2019-08-12 10:22:16,581 : INFO : PROGRESS: at sentence #700000, processed 9889576 words, keeping 59009 word types\n",
            "2019-08-12 10:22:16,623 : INFO : PROGRESS: at sentence #710000, processed 10027387 words, keeping 59414 word types\n",
            "2019-08-12 10:22:16,663 : INFO : PROGRESS: at sentence #720000, processed 10163662 words, keeping 59863 word types\n",
            "2019-08-12 10:22:16,702 : INFO : PROGRESS: at sentence #730000, processed 10297775 words, keeping 60251 word types\n",
            "2019-08-12 10:22:16,740 : INFO : PROGRESS: at sentence #740000, processed 10429991 words, keeping 60778 word types\n",
            "2019-08-12 10:22:16,780 : INFO : PROGRESS: at sentence #750000, processed 10569453 words, keeping 61361 word types\n",
            "2019-08-12 10:22:16,818 : INFO : PROGRESS: at sentence #760000, processed 10704263 words, keeping 61846 word types\n",
            "2019-08-12 10:22:16,860 : INFO : PROGRESS: at sentence #770000, processed 10840011 words, keeping 62394 word types\n",
            "2019-08-12 10:22:16,879 : INFO : collected 62533 word types from a corpus of 10878240 raw words and 772819 sentences\n",
            "2019-08-12 10:22:16,880 : INFO : Loading a fresh vocabulary\n",
            "2019-08-12 10:22:16,948 : INFO : effective_min_count=5 retains 15835 unique words (25% of original 62533, drops 46698)\n",
            "2019-08-12 10:22:16,950 : INFO : effective_min_count=5 leaves 10810970 word corpus (99% of original 10878240, drops 67270)\n",
            "2019-08-12 10:22:17,015 : INFO : deleting the raw counts dictionary of 62533 items\n",
            "2019-08-12 10:22:17,018 : INFO : sample=0.001 downsamples 56 most-common words\n",
            "2019-08-12 10:22:17,019 : INFO : downsampling leaves estimated 7243906 word corpus (67.0% of prior 10810970)\n",
            "2019-08-12 10:22:17,082 : INFO : estimated required memory for 15835 words and 64 dimensions: 16025020 bytes\n",
            "2019-08-12 10:22:17,084 : INFO : resetting layer weights\n",
            "2019-08-12 10:22:17,255 : INFO : training model with 3 workers on 15835 vocabulary and 64 features, using sg=0 hs=0 sample=0.001 negative=5 window=8\n",
            "2019-08-12 10:22:18,275 : INFO : EPOCH 1 - PROGRESS: at 8.52% examples, 655434 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:19,283 : INFO : EPOCH 1 - PROGRESS: at 17.04% examples, 648148 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:20,297 : INFO : EPOCH 1 - PROGRESS: at 26.06% examples, 653700 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:21,298 : INFO : EPOCH 1 - PROGRESS: at 35.06% examples, 656051 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:22,312 : INFO : EPOCH 1 - PROGRESS: at 44.37% examples, 657156 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:23,322 : INFO : EPOCH 1 - PROGRESS: at 53.75% examples, 658389 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:24,332 : INFO : EPOCH 1 - PROGRESS: at 63.12% examples, 658321 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:25,340 : INFO : EPOCH 1 - PROGRESS: at 72.48% examples, 658560 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:26,345 : INFO : EPOCH 1 - PROGRESS: at 81.94% examples, 658842 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:27,346 : INFO : EPOCH 1 - PROGRESS: at 91.42% examples, 659398 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:28,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-08-12 10:22:28,239 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-08-12 10:22:28,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-08-12 10:22:28,249 : INFO : EPOCH - 1 : training on 10878240 raw words (7244282 effective words) took 11.0s, 659609 effective words/s\n",
            "2019-08-12 10:22:29,274 : INFO : EPOCH 2 - PROGRESS: at 8.51% examples, 656510 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:30,283 : INFO : EPOCH 2 - PROGRESS: at 17.04% examples, 648686 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:31,287 : INFO : EPOCH 2 - PROGRESS: at 25.96% examples, 653713 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:32,304 : INFO : EPOCH 2 - PROGRESS: at 35.06% examples, 655436 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:33,311 : INFO : EPOCH 2 - PROGRESS: at 44.19% examples, 654813 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:34,313 : INFO : EPOCH 2 - PROGRESS: at 53.48% examples, 656194 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:35,315 : INFO : EPOCH 2 - PROGRESS: at 62.84% examples, 657194 words/s, in_qsize 4, out_qsize 0\n",
            "2019-08-12 10:22:36,318 : INFO : EPOCH 2 - PROGRESS: at 72.12% examples, 657030 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:37,325 : INFO : EPOCH 2 - PROGRESS: at 81.57% examples, 657317 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:38,328 : INFO : EPOCH 2 - PROGRESS: at 91.04% examples, 657851 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:39,256 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-08-12 10:22:39,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-08-12 10:22:39,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-08-12 10:22:39,280 : INFO : EPOCH - 2 : training on 10878240 raw words (7243027 effective words) took 11.0s, 657684 effective words/s\n",
            "2019-08-12 10:22:40,294 : INFO : EPOCH 3 - PROGRESS: at 8.16% examples, 633535 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:41,305 : INFO : EPOCH 3 - PROGRESS: at 16.95% examples, 646341 words/s, in_qsize 4, out_qsize 1\n",
            "2019-08-12 10:22:42,308 : INFO : EPOCH 3 - PROGRESS: at 25.88% examples, 652511 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:43,310 : INFO : EPOCH 3 - PROGRESS: at 34.89% examples, 655091 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:44,317 : INFO : EPOCH 3 - PROGRESS: at 44.11% examples, 655993 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:45,326 : INFO : EPOCH 3 - PROGRESS: at 53.39% examples, 656459 words/s, in_qsize 4, out_qsize 1\n",
            "2019-08-12 10:22:46,329 : INFO : EPOCH 3 - PROGRESS: at 62.83% examples, 658211 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:47,335 : INFO : EPOCH 3 - PROGRESS: at 72.21% examples, 658397 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:48,347 : INFO : EPOCH 3 - PROGRESS: at 81.66% examples, 658219 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:49,368 : INFO : EPOCH 3 - PROGRESS: at 91.23% examples, 658212 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:50,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-08-12 10:22:50,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-08-12 10:22:50,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-08-12 10:22:50,313 : INFO : EPOCH - 3 : training on 10878240 raw words (7242790 effective words) took 11.0s, 657176 effective words/s\n",
            "2019-08-12 10:22:51,325 : INFO : EPOCH 4 - PROGRESS: at 8.51% examples, 660951 words/s, in_qsize 6, out_qsize 0\n",
            "2019-08-12 10:22:52,334 : INFO : EPOCH 4 - PROGRESS: at 17.30% examples, 661166 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:53,336 : INFO : EPOCH 4 - PROGRESS: at 26.24% examples, 662390 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:54,346 : INFO : EPOCH 4 - PROGRESS: at 35.25% examples, 661211 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:55,357 : INFO : EPOCH 4 - PROGRESS: at 44.46% examples, 660534 words/s, in_qsize 4, out_qsize 1\n",
            "2019-08-12 10:22:56,359 : INFO : EPOCH 4 - PROGRESS: at 53.84% examples, 662065 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:57,362 : INFO : EPOCH 4 - PROGRESS: at 63.11% examples, 661118 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:58,384 : INFO : EPOCH 4 - PROGRESS: at 72.58% examples, 660630 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:22:59,386 : INFO : EPOCH 4 - PROGRESS: at 82.13% examples, 661527 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:00,401 : INFO : EPOCH 4 - PROGRESS: at 91.52% examples, 660229 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:01,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-08-12 10:23:01,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-08-12 10:23:01,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-08-12 10:23:01,322 : INFO : EPOCH - 4 : training on 10878240 raw words (7243274 effective words) took 11.0s, 658700 effective words/s\n",
            "2019-08-12 10:23:02,359 : INFO : EPOCH 5 - PROGRESS: at 8.59% examples, 652058 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:03,366 : INFO : EPOCH 5 - PROGRESS: at 17.49% examples, 660057 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:04,368 : INFO : EPOCH 5 - PROGRESS: at 26.42% examples, 661793 words/s, in_qsize 6, out_qsize 0\n",
            "2019-08-12 10:23:05,382 : INFO : EPOCH 5 - PROGRESS: at 35.44% examples, 660060 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:06,389 : INFO : EPOCH 5 - PROGRESS: at 44.64% examples, 660123 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:07,392 : INFO : EPOCH 5 - PROGRESS: at 53.94% examples, 660431 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:08,396 : INFO : EPOCH 5 - PROGRESS: at 63.39% examples, 661534 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:09,401 : INFO : EPOCH 5 - PROGRESS: at 72.57% examples, 659801 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:10,406 : INFO : EPOCH 5 - PROGRESS: at 81.95% examples, 659254 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:11,409 : INFO : EPOCH 5 - PROGRESS: at 91.04% examples, 656995 words/s, in_qsize 5, out_qsize 0\n",
            "2019-08-12 10:23:12,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-08-12 10:23:12,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-08-12 10:23:12,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-08-12 10:23:12,340 : INFO : EPOCH - 5 : training on 10878240 raw words (7242928 effective words) took 11.0s, 658144 effective words/s\n",
            "2019-08-12 10:23:12,343 : INFO : training on a 54391200 raw words (36216301 effective words) took 55.1s, 657434 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK96YCTL__0B",
        "colab_type": "text"
      },
      "source": [
        "With the trained model, we now can do some interesting exercises:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpqAYK8d__0C",
        "colab_type": "code",
        "outputId": "e3bafe78-c55a-434b-bd4a-40069dace389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "# e.g. look up synonyms \n",
        "\n",
        "model.most_similar('perfect')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-12 10:25:17,865 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ideal', 0.8118923902511597),\n",
              " ('fantastic', 0.7782608270645142),\n",
              " ('terrific', 0.7630852460861206),\n",
              " ('prime', 0.7581384778022766),\n",
              " ('great', 0.72962486743927),\n",
              " ('superb', 0.7247453927993774),\n",
              " ('fabulous', 0.7136520147323608),\n",
              " ('wonderful', 0.6941670775413513),\n",
              " ('brilliant', 0.6858558654785156),\n",
              " ('phenomenal', 0.6433806419372559)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTeJD4Rx__0F",
        "colab_type": "code",
        "outputId": "a046c650-f20b-4d3d-a360-46ad1f3c8ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar('dirty')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dusty', 0.7931612730026245),\n",
              " ('broken', 0.7893902063369751),\n",
              " ('moldy', 0.7801511287689209),\n",
              " ('mold', 0.7728430032730103),\n",
              " ('filthy', 0.7682775259017944),\n",
              " ('wet', 0.7668278813362122),\n",
              " ('holes', 0.7524440288543701),\n",
              " ('hairs', 0.7514322996139526),\n",
              " ('stained', 0.750318169593811),\n",
              " ('dust', 0.7445692420005798)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9_wSgm5__0J",
        "colab_type": "code",
        "outputId": "71d19eed-718b-47cb-ebb4-eeff0777a1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we can print some of the often seen terms\n",
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.', 'her', 'extremely', 'though', 'far', 'hour', 'natural', 'drink', 'waiting', 'un']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZfh047I__0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the model can also return our word-vectors\n",
        "\n",
        "word_vectors = model.vectors[[model.vocab[word].index for word in words]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgacOfCZ__0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to visualize the vectors (not easy at all)\n",
        "\n",
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLSElJjU__0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can project the word vectors into 2dimensinoal space using the new UMAP library\n",
        "import umap\n",
        "\n",
        "def get_umap_projection(word_vectors):\n",
        "    vecs = umap.UMAP(n_neighbors=15, metric='cosine').fit_transform(word_vectors)\n",
        "    return vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaHkGmat__0Q",
        "colab_type": "code",
        "outputId": "d757fd6e-ad34-4aee-f7bf-fdefba3bb5b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "word_umap = get_umap_projection(word_vectors[:1000])\n",
        "draw_vectors(word_umap[:, 0], word_umap[:, 1], color='blue', token=words)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"9e730668-b769-42b7-95ce-69328043c144\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"662bef16-6305-45e9-b1c9-660a5b9e300b\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"id\":\"1020\",\"type\":\"Grid\"},{\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"id\":\"1039\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1043\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1003\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1007\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{\"formatter\":{\"id\":\"1047\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1037\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1040\",\"type\":\"CDSView\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1041\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"token\":[\".\",\"the\",\"and\",\",\",\"a\",\"to\",\"is\",\"was\",\"in\",\"!\",\"of\",\"very\",\"great\",\"i\",\"we\",\"it\",\"for\",\"place\",\"apartment\",\"with\",\"stay\",\"you\",\"location\",\"this\",\"city\",\"'s\",\"at\",\"there\",\"our\",\"were\",\"had\",\"host\",\"that\",\"clean\",\"as\",\"would\",\"are\",\"mexico\",\"but\",\"us\",\"nice\",\"on\",\"so\",\"my\",\")\",\"\\u2019\",\"an\",\"all\",\"recommend\",\"from\",\"restaurants\",\"comfortable\",\"everything\",\"(\",\"perfect\",\"really\",\"not\",\"be\",\"again\",\"have\",\"good\",\"if\",\"neighborhood\",\"beautiful\",\"also\",\"well\",\"close\",\"time\",\"here\",\"amazing\",\"safe\",\"definitely\",\"room\",\"helpful\",\"has\",\"s\",\"easy\",\"out\",\"n't\",\"located\",\"super\",\"he\",\"area\",\"home\",\"space\",\"me\",\"highly\",\"one\",\"just\",\"she\",\"which\",\"walking\",\"or\",\"will\",\"wonderful\",\"can\",\"they\",\"when\",\"-\",\"building\",\"her\",\"like\",\"around\",\"get\",\"walk\",\"staying\",\"even\",\"night\",\"back\",\"best\",\"excellent\",\"by\",\"some\",\"could\",\"about\",\"distance\",\"quiet\",\"many\",\"lovely\",\"street\",\"house\",\"only\",\"loved\",\"need\",\"hosts\",\"friendly\",\"water\",\"made\",\"condesa\",\"his\",\":\",\"do\",\"spacious\",\"more\",\"felt\",\"day\",\"bed\",\"no\",\"bars\",\"up\",\"did\",\"airbnb\",\"much\",\"always\",\"stayed\",\"any\",\"your\",\"needed\",\"roma\",\"away\",\"than\",\"check\",\"responsive\",\"experience\",\"right\",\"metro\",\"two\",\"other\",\"little\",\"kitchen\",\"lots\",\"places\",\"enjoyed\",\"fantastic\",\"next\",\"within\",\"feel\",\"during\",\"communication\",\"thank\",\"quick\",\"lot\",\"what\",\"people\",\"make\",\"go\",\"few\",\"thanks\",\"t\",\"come\",\"food\",\"sure\",\"cdmx\",\"coffee\",\"who\",\"trip\",\"kind\",\"questions\",\"most\",\"visit\",\"la\",\"before\",\"their\",\"bathroom\",\"small\",\"&\",\"after\",\"first\",\"days\",\"recommended\",\"extremely\",\"awesome\",\"better\",\"amenities\",\"convenient\",\"arrival\",\"stylish\",\"shops\",\"things\",\"near\",\"want\",\"hot\",\"too\",\"nearby\",\"bit\",\"accommodating\",\"central\",\"overall\",\"uber\",\"every\",\"big\",\"where\",\"noise\",\"modern\",\"shower\",\"light\",\"such\",\"door\",\"because\",\"available\",\"absolutely\",\"itself\",\"...\",\"gave\",\"short\",\"enough\",\"cozy\",\"family\",\"2\",\"cool\",\"local\",\"help\",\"view\",\"provided\",\"welcoming\",\"see\",\"de\",\"park\",\"value\",\"morning\",\"arrived\",\"spot\",\"cafes\",\"airport\",\"plenty\",\"recommendations\",\"flat\",\"minutes\",\"while\",\"looking\",\"way\",\"love\",\"bedroom\",\"been\",\"being\",\"decorated\",\"large\",\";\",\"security\",\"private\",\"anyone\",\"exactly\",\"quite\",\"late\",\"pictures\",\"find\",\"tips\",\"part\",\"able\",\"access\",\"cute\",\"them\",\"couple\",\"5\",\"both\",\"floor\",\"full\",\"use\",\"got\",\"etc\",\"eat\",\"secure\",\"beds\",\"went\",\"living\",\"center\",\"heart\",\"attentive\",\"check-in\",\"how\",\"though\",\"blocks\",\"carlos\",\"terrace\",\"wifi\",\"its\",\"pretty\",\"parks\",\"warm\",\"return\",\"norte\",\"breakfast\",\"minute\",\"early\",\"'re\",\"friends\",\"work\",\"anything\",\"person\",\"into\",\"--\",\"long\",\"windows\",\"new\",\"ever\",\"rooftop\",\"price\",\"3\",\"open\",\"quickly\",\"juan\",\"helped\",\"having\",\"neighbourhood\",\"outside\",\"left\",\"issue\",\"polanco\",\"incredible\",\"y\",\"over\",\"explore\",\"main\",\"respond\",\"take\",\"times\",\"equipped\",\"going\",\"doorman\",\"never\",\"down\",\"especially\",\"station\",\"problem\",\"perfectly\",\"described\",\"nights\",\"welcome\",\"enjoy\",\"exploring\",\"book\",\"incredibly\",\"comfy\",\"since\",\"reservation\",\"balcony\",\"needs\",\"met\",\"let\",\"block\",\"top\",\"centrally\",\"off\",\"know\",\"own\",\"el\",\"corner\",\"flight\",\"sleep\",\"thing\",\"huge\",\"photos\",\"guests\",\"town\",\"ca\",\"took\",\"found\",\"week\",\"across\",\"through\",\"noisy\",\"hospitality\",\"museums\",\"fast\",\"however\",\"visiting\",\"issues\",\"public\",\"him\",\"rooms\",\"far\",\"easily\",\"plus\",\"'ve\",\"extra\",\"meet\",\"hope\",\"studio\",\"francisco\",\"communicative\",\"appreciated\",\"'d\",\"attractions\",\"coyoacan\",\"store\",\"second\",\"say\",\"chapultepec\",\"loud\",\"front\",\"historic\",\"fun\",\"getting\",\"areas\",\"restaurant\",\"happy\",\"expected\",\"gorgeous\",\"group\",\"throughout\",\"charming\",\"patio\",\"posting\",\"several\",\"transportation\",\"10\",\"4\",\"canceled\",\"apt\",\"neighborhoods\",\"pleasant\",\"walkable\",\"am\",\"although\",\"automated\",\"may\",\"still\",\"staff\",\"maria\",\"loft\",\"hours\",\"cold\",\"views\",\"might\",\"came\",\"centro\",\"roof\",\"last\",\"without\",\"used\",\"coming\",\"truly\",\"suggestions\",\"shopping\",\"'ll\",\"flexible\",\"then\",\"towels\",\"responded\",\"communicate\",\"wanted\",\"ideal\",\"including\",\"soon\",\"tv\",\"market\",\"service\",\"above\",\"stores\",\"art\",\"luis\",\"look\",\"middle\",\"leave\",\"does\",\"friend\",\"another\",\"makes\",\"beyond\",\"busy\",\"unit\",\"bedrooms\",\"making\",\"traveling\",\"pool\",\"beautifully\",\"each\",\"thoughtful\",\"whole\",\"sweet\",\"hour\",\"subway\",\"zocalo\",\"touches\",\"old\",\"''\",\"ride\",\"bright\",\"care\",\"give\",\"think\",\"``\",\"fresh\",\"three\",\"should\",\"tons\",\"pablo\",\"hotel\",\"worked\",\"totally\",\"fine\",\"delicious\",\"air\",\"bathrooms\",\"24\",\"offered\",\"supermarket\",\"looks\",\"same\",\"inside\",\"df\",\"future\",\"touch\",\"asked\",\"information\",\"spent\",\"internet\",\"'m\",\"everywhere\",\"spots\",\"simple\",\"favorite\",\"wait\",\"travel\",\"mexican\",\"bus\",\"didn\",\"checked\",\"walked\",\"nicely\",\"something\",\"downtown\",\"interesting\",\"reforma\",\"1\",\"options\",\"rest\",\"almost\",\"muy\",\"privacy\",\"ask\",\"gracias\",\"due\",\"feels\",\"bring\",\"taxi\",\"entire\",\"until\",\"base\",\"longer\",\"downstairs\",\"re\",\"hip\",\"once\",\"different\",\"min\",\"keep\",\"pressure\",\"hear\",\"size\",\"immediately\",\"grocery\",\"property\",\"end\",\"messages\",\"rodrigo\",\"streets\",\"those\",\"keys\",\"someone\",\"stairs\",\"weekend\",\"everyone\",\"traffic\",\"upon\",\"decor\",\"100\",\"garden\",\"'\",\"hidden\",\"natural\",\"%\",\"working\",\"accessible\",\"wish\",\"hugo\",\"conveniently\",\"dog\",\"jorge\",\"gym\",\"hard\",\"note\",\"cafe\",\"between\",\"spend\",\"husband\",\"fully\",\"kept\",\"listing\",\"offer\",\"alejandro\",\"design\",\"alex\",\"tourist\",\"gracious\",\"set\",\"high\",\"stop\",\"situated\",\"details\",\"en\",\"basic\",\"else\",\"laundry\",\"answer\",\"evening\",\"booked\",\"relax\",\"window\",\"major\",\"spanish\",\"relaxing\",\"english\",\"luggage\",\"anywhere\",\"welcomed\",\"live\",\"parque\",\"life\",\"checking\",\"hospitable\",\"peaceful\",\"nothing\",\"said\",\"business\",\"casa\",\"ready\",\"worth\",\"apartments\",\"actually\",\"shared\",\"jose\",\"liked\",\"sites\",\"booking\",\"cleaning\",\"key\",\"yet\",\"24/7\",\"museum\",\"problems\",\"convenience\",\"real\",\"try\",\"cheap\",\"forward\",\"special\",\"fridge\",\"dogs\",\"deal\",\"stocked\",\"furnished\",\"angel\",\"advice\",\"unique\",\"less\",\"plan\",\"process\",\"david\",\"shop\",\"answered\",\"tour\",\"others\",\"fabulous\",\"trendy\",\"ana\",\"cook\",\"thought\",\"money\",\"guest\",\"drink\",\"elevator\",\"outstanding\",\"contact\",\"6\",\"music\",\"don\",\"bad\",\"beat\",\"advertised\",\"these\",\"diego\",\"designed\",\"victor\",\"heater\",\"neighbors\",\"steps\",\"style\",\"machine\",\"already\",\"eduardo\",\"mind\",\"lively\",\"showed\",\"pleasure\",\"markets\",\"district\",\"expectations\",\"sleeping\",\"alejandra\",\"probably\",\"courtyard\",\"dining\",\"phone\",\"ve\",\"show\",\"provide\",\"accurate\",\"construction\",\"ricardo\",\"sights\",\"miguel\",\"four\",\"earplugs\",\"que\",\"mariana\",\"d\",\"side\",\"plants\",\"via\",\"15\",\"prompt\",\"condo\",\"nightlife\",\"fan\",\"greeted\",\"furniture\",\"travelers\",\"dinner\",\"using\",\"artes\",\"entrance\",\"bar\",\"cooking\",\"fruit\",\"es\",\"centre\",\"otherwise\",\"start\",\"unfortunately\",\"transport\",\"guard\",\"complex\",\"gets\",\"?\",\"netflix\",\"appartment\",\"dryer\",\"possible\",\"must\",\"completely\",\"wife\",\"check-out\",\"month\",\"expect\",\"choice\",\"toilet\",\"tacos\",\"smooth\",\"common\",\"rodolfo\",\"coyoac\\u00e1n\",\"outdoor\",\"parts\",\"rosa\",\"slept\",\"snacks\",\"breeze\",\"point\",\"parking\",\"waiting\",\"fernando\",\"appointed\",\"bags\",\"metrobus\",\"later\",\"showers\",\"gem\",\"literally\",\"historical\",\"hang\",\"pictured\",\"responses\",\"option\",\"kids\",\"sleeper\",\"question\",\"hesitate\",\"$\",\"response\",\"spotless\",\"reviews\",\"allowed\",\"important\",\"weeks\",\"case\",\"description\",\"doormen\",\"certainly\",\"stunning\",\"frida\",\"historico\",\"doors\",\"stars\",\"ok\",\"guy\",\"whenever\",\"reach\",\"filled\",\"clear\",\"told\",\"put\",\"attention\",\"ll\",\"desk\",\"five\",\"traveler\",\"given\",\"martha\",\"bonus\",\"solo\",\"superb\",\"enjoyable\",\"myself\",\"promptly\",\"single\",\"bellas\",\"list\",\"couldn\",\"willing\",\"quality\",\"along\",\"detail\",\"car\",\"instructions\",\"zona\",\"taco\",\"taking\",\"surrounding\",\"table\",\"andres\",\"roberto\",\"world\",\"walls\",\"plaza\",\"hector\",\"gabriela\",\"road\",\"drinks\",\"simply\",\"generous\",\"works\",\"deck\",\"daniel\",\"despite\",\"now\",\"year\",\"/\",\"20\",\"aware\",\"interior\",\"washer\",\"mentioned\",\"prepared\",\"sheets\",\"guide\",\"vacation\",\"oasis\",\"terrific\",\"cosy\",\"un\",\"upstairs\",\"difficult\",\"useful\",\"karla\",\"tidy\",\"couples\",\"fact\",\"adorable\",\"washing\",\"pick\",\"calm\",\"owner\",\"number\",\"call\",\"speak\",\"affordable\",\"marco\",\"wine\",\"hostess\",\"either\",\"closet\",\"personal\",\"chance\",\"recomendable\",\"done\",\"stations\",\"sent\",\"ended\",\"looked\",\"giving\",\"soap\",\"alone\",\"ear\",\"condessa\",\"monica\",\"party\",\"feeling\",\"plugs\",\"m\",\"below\",\"consider\",\"surrounded\",\"accommodate\",\"7\",\"bother\",\"maybe\",\"added\",\"mention\",\"included\",\"arrive\",\"beer\",\"sun\",\"excelente\",\"months\",\"spaces\",\"level\",\"minor\",\"planning\",\"alberto\",\"fixed\",\"true\",\"m\\u00e9xico\",\"blankets\",\"closed\",\"comes\",\"buy\",\"con\",\"free\",\"pillows\",\"drinking\",\"share\",\"mall\",\"daily\",\"called\",\"vibe\",\"manuel\",\"provides\",\"facilities\",\"communicating\",\"accommodation\",\"half\",\"miss\",\"guys\",\"general\",\"offers\",\"taken\",\"mins\",\"residential\",\"team\",\"locations\",\"books\",\"run\",\"comfort\",\"stuff\",\"boyfriend\",\"luz\",\"together\",\"accommodations\",\"moment\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1049\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1050\",\"type\":\"UnionRenderers\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1043\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1038\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"},{\"id\":\"1041\",\"type\":\"HoverTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"Selection\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
              "  var render_items = [{\"docid\":\"662bef16-6305-45e9-b1c9-660a5b9e300b\",\"roots\":{\"1002\":\"9e730668-b769-42b7-95ce-69328043c144\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        embed_document(root);\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "      attempts++;\n",
              "      if (attempts > 100) {\n",
              "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting.figure.Figure\">Figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1002', <span id=\"1107\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='1011', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">h_symmetry&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='1016', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;{'value': '#e5e5e5'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;{'value': 1},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_height&nbsp;=&nbsp;400,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_width&nbsp;=&nbsp;600,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[LinearAxis(id='1011', ...), Grid(id='1015', ...), LinearAxis(id='1016', ...), Grid(id='1020', ...), BoxAnnotation(id='1029', ...), GlyphRenderer(id='1039', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'fixed',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='1043', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='1027', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">v_symmetry&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='1003', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='1007', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='1005', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='1009', ...))</div></div></div>\n",
              "<script>\n",
              "(function() {\n",
              "  var expanded = false;\n",
              "  var ellipsis = document.getElementById(\"1107\");\n",
              "  ellipsis.addEventListener(\"click\", function() {\n",
              "    var rows = document.getElementsByClassName(\"1106\");\n",
              "    for (var i = 0; i < rows.length; i++) {\n",
              "      var el = rows[i];\n",
              "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
              "    }\n",
              "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
              "    expanded = !expanded;\n",
              "  });\n",
              "})();\n",
              "</script>\n"
            ],
            "text/plain": [
              "Figure(id='1002', ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVzMkO5N__0T",
        "colab_type": "text"
      },
      "source": [
        "## Case 3: Predicting categories with a self-trained model\n",
        "\n",
        "In this case we will use work from Upwork.com (from a recent research paper) to predict task-categories.\n",
        "Upwork https://www.upwork.com is a platform that connects freelancers with short term employers online. The dataset contains text, describing the task, as well as a category task. Unfortunately, not all task descriptions had these category labels. This is where we will use NLP + ML to create the misssing labels. \n",
        "\n",
        "Recent paper with Mareike Seifried and Tobias Kretschmer\n",
        "https://conference.druid.dk/acc_papers/48ox0g0vwmp0vvx8gj7lzwhbimflf0.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GasJVUnX__0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the data\n",
        "data = pd.read_csv('upwork_aom_300k.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shp5-NZR__0V",
        "colab_type": "code",
        "outputId": "9ec52a09-98de-482e-9f3e-a1a150007071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#let's check it\n",
        "data.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>as_opening_title</th>\n",
              "      <th>main_category</th>\n",
              "      <th>sub_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>968913</td>\n",
              "      <td>Mailchimp Marketing Assistant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1855958</td>\n",
              "      <td>Manually submit 2000 names to an online form</td>\n",
              "      <td>Admin Support</td>\n",
              "      <td>Data Entry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>109271</td>\n",
              "      <td>Design</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1349850</td>\n",
              "      <td>Cool and Fun Graphic Designer/Illustrator need...</td>\n",
              "      <td>Design &amp; Creative</td>\n",
              "      <td>Graphic Design</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>729567</td>\n",
              "      <td>Html/css/js</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...    sub_category\n",
              "0      968913  ...             NaN\n",
              "1     1855958  ...      Data Entry\n",
              "2      109271  ...             NaN\n",
              "3     1349850  ...  Graphic Design\n",
              "4      729567  ...             NaN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "978rL5lG__0Y",
        "colab_type": "code",
        "outputId": "6818354d-2d10-48a1-e07a-6cee96aa2c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#some descriptives\n",
        "\n",
        "data.info()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300000 entries, 0 to 299999\n",
            "Data columns (total 4 columns):\n",
            "Unnamed: 0          300000 non-null int64\n",
            "as_opening_title    299998 non-null object\n",
            "main_category       87967 non-null object\n",
            "sub_category        87967 non-null object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 9.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwbltJ0n__0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selecting the empty ones\n",
        "\n",
        "data_subset_empty = data[data['main_category'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ts8krXq__0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selecting the complete ones\n",
        "\n",
        "data_full = data[~data['main_category'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWDxFj2V__0g",
        "colab_type": "code",
        "outputId": "b4990df9-b742-4193-80a3-fe31712f13e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#Some descriptives of the complete table\n",
        "\n",
        "data_full.info()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 87967 entries, 1 to 299998\n",
            "Data columns (total 4 columns):\n",
            "Unnamed: 0          87967 non-null int64\n",
            "as_opening_title    87967 non-null object\n",
            "main_category       87967 non-null object\n",
            "sub_category        87967 non-null object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 3.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8WKesSr__0i",
        "colab_type": "code",
        "outputId": "b058d6fd-8ae9-4529-8c4d-20ea2a304c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "# Print out the different categories of tasks\n",
        "\n",
        "for i in data_full['main_category'].unique():\n",
        "    print(i)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Admin Support\n",
            "Design & Creative\n",
            "Sales & Marketing\n",
            "Writing\n",
            "Web, Mobile & Software Dev\n",
            "Accounting & Consulting\n",
            "Data Science & Analytics\n",
            "IT & Networking\n",
            "Translation\n",
            "Engineering & Architecture\n",
            "Customer Service\n",
            "Legal\n",
            "Web & Mobile Development\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmlLC5mu51y4",
        "colab_type": "text"
      },
      "source": [
        "Now we need to construct our dependant and indepandant variables\n",
        "The independant will be the vector representations of the texts\n",
        "The dependant variable will be a the category of jobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ6vFtDC__0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import encoders for the dependant variable\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpSvckSB__0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "fbcc0a5a-435f-4927-90ef-50c63f868911"
      },
      "source": [
        "# encode the dependant into dummy variables\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "onehot = OneHotEncoder()\n",
        "\n",
        "encoded = encoder.fit_transform(data_full['main_category']) #categorical index\n",
        "y = onehot.fit_transform(encoded.reshape(-1,1)) # dummy matrix"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuoOMUHn__0m",
        "colab_type": "text"
      },
      "source": [
        "We will be using spacy: https://spacy.io\n",
        "It is a moden and fast NLP library that allows to do NLP tasks without engaging too much with linguistics and low-level tasks\n",
        "you can download more and other models (also spanish) here https://spacy.io/usage/models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYh_G7XA__0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download and install a large spacy model. For simple tasks, the small model\n",
        "# spacy.load('en') is OK and already installed\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOusSZc-__0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load up a pretrained (there are also spanish models available)\n",
        "\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emoR972J__0p",
        "colab_type": "text"
      },
      "source": [
        "In the next step we will use Spacy to work with the language data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dSXoSsl__0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizing the text-data\n",
        "vector_list = []\n",
        "\n",
        "for doc in nlp.pipe(data_full['as_opening_title'], n_threads=4, batch_size=10000):\n",
        "    vector_list.append(doc.vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8BLdtB___0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assamble the list of vectors into a matrix\n",
        "X = np.vstack(vector_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etyp95co5yKf",
        "colab_type": "text"
      },
      "source": [
        "Having created the variables, we can now split the dataset and train some models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv2xTASW__0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting the data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNm68sVq__0u",
        "colab_type": "code",
        "outputId": "fdf7cae6-6b28-40be-c9eb-89b7833721a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Training a logistic regression\n",
        "\n",
        "classifier = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPmC8T2K__0y",
        "colab_type": "code",
        "outputId": "6f458557-5a9c-4923-cd5c-9cce5bf333cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# How are we doing?\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "classes_list = y_test.tolist() + y_pred.tolist()\n",
        "\n",
        "labels = sorted(set(classes_list))\n",
        "targets = encoder.inverse_transform(labels)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names = targets))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Accounting & Consulting       0.61      0.42      0.50       266\n",
            "             Admin Support       0.65      0.68      0.67      2065\n",
            "          Customer Service       0.59      0.36      0.45       113\n",
            "  Data Science & Analytics       0.49      0.17      0.25       253\n",
            "         Design & Creative       0.82      0.85      0.84      3774\n",
            "Engineering & Architecture       0.68      0.46      0.55       337\n",
            "           IT & Networking       0.65      0.40      0.50       382\n",
            "                     Legal       0.65      0.41      0.50        49\n",
            "         Sales & Marketing       0.67      0.59      0.62      1282\n",
            "               Translation       0.87      0.84      0.85       826\n",
            "  Web & Mobile Development       0.00      0.00      0.00         2\n",
            "Web, Mobile & Software Dev       0.81      0.89      0.85      5424\n",
            "                   Writing       0.81      0.82      0.81      2821\n",
            "\n",
            "                  accuracy                           0.78     17594\n",
            "                 macro avg       0.64      0.53      0.57     17594\n",
            "              weighted avg       0.77      0.78      0.77     17594\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs6aBULsHcqo",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will be training an artificial neural network\n",
        "We will be using Keras for setting it up and training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0E0kv6q__0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed5a9962-a608-4680-e285-79f54c8de7f5"
      },
      "source": [
        "# Importing the keras library for deep learning\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa6xQBw-fAMx",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/600px-Colored_neural_network.svg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vblnvN-j__1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential() \n",
        "\n",
        "#### RED ####\n",
        "classifier.add(Dense(units = 256, activation='relu', input_dim = 300))\n",
        "\n",
        "#### BLUE ####\n",
        "classifier.add(Dropout(rate = 0.3))\n",
        "classifier.add(Dense(units = 512, activation='relu'))\n",
        "classifier.add(Dropout(rate = 0.1))\n",
        "classifier.add(Dense(units = 64,  activation='relu'))\n",
        "\n",
        "\n",
        "#### GREEN ####\n",
        "classifier.add(Dense(units = 13, activation='softmax'))\n",
        "\n",
        "\n",
        "#### COMPILE ####\n",
        "classifier.compile(optimizer=\"adam\", loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNARZQ7Y__1F",
        "colab_type": "code",
        "outputId": "0279300a-d7bd-496d-8c0f-818e6a4d98fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               77056     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 13)                845       \n",
            "=================================================================\n",
            "Total params: 242,317\n",
            "Trainable params: 242,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLC6X0g2__1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4VaQzdl__1H",
        "colab_type": "code",
        "outputId": "751e92e7-dc8b-4a21-a3c6-2b8b0f723b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "history = classifier.fit(X_train, y_train, batch_size= 500, epochs= 10, validation_data=(X_test, y_test))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 12:38:40.774601 139647347070848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 70373 samples, validate on 17594 samples\n",
            "Epoch 1/10\n",
            "70373/70373 [==============================] - 5s 74us/step - loss: 1.0233 - acc: 0.6911 - val_loss: 0.7392 - val_acc: 0.7770\n",
            "Epoch 2/10\n",
            "70373/70373 [==============================] - 4s 61us/step - loss: 0.7462 - acc: 0.7725 - val_loss: 0.6884 - val_acc: 0.7888\n",
            "Epoch 3/10\n",
            "70373/70373 [==============================] - 4s 60us/step - loss: 0.7010 - acc: 0.7861 - val_loss: 0.6652 - val_acc: 0.7953\n",
            "Epoch 4/10\n",
            "70373/70373 [==============================] - 4s 61us/step - loss: 0.6717 - acc: 0.7949 - val_loss: 0.6539 - val_acc: 0.8006\n",
            "Epoch 5/10\n",
            "70373/70373 [==============================] - 4s 58us/step - loss: 0.6528 - acc: 0.8006 - val_loss: 0.6479 - val_acc: 0.8009\n",
            "Epoch 6/10\n",
            "70373/70373 [==============================] - 4s 56us/step - loss: 0.6364 - acc: 0.8042 - val_loss: 0.6372 - val_acc: 0.8031\n",
            "Epoch 7/10\n",
            "70373/70373 [==============================] - 4s 56us/step - loss: 0.6209 - acc: 0.8081 - val_loss: 0.6316 - val_acc: 0.8044\n",
            "Epoch 8/10\n",
            "70373/70373 [==============================] - 4s 55us/step - loss: 0.6051 - acc: 0.8136 - val_loss: 0.6236 - val_acc: 0.8060\n",
            "Epoch 9/10\n",
            "70373/70373 [==============================] - 4s 56us/step - loss: 0.5938 - acc: 0.8161 - val_loss: 0.6317 - val_acc: 0.8049\n",
            "Epoch 10/10\n",
            "70373/70373 [==============================] - 4s 55us/step - loss: 0.5817 - acc: 0.8201 - val_loss: 0.6157 - val_acc: 0.8085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOp2vTcC__1J",
        "colab_type": "code",
        "outputId": "6709ed1d-e5f7-4998-94dc-6077c682fe6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "pd.DataFrame(history.history)[['acc','val_acc']].plot()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01b7a0de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEBCAYAAACXArmGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt8VOW97/HPzJpM7pkkk9skAQIB\nYUACLWzxAkVAhdrQsEu13bFu926L+0jVak+leCkXtbrDfh1b20Kttt5KX+2pUsWklCLVHsUiWi/h\nEklJCATI5DKTTC6Ty8ystc4fEwYC0UwgYSbJ7/165ZXMypo1vyH6fGc9z3rWY9B1XUcIIYQAjOEu\nQAghROSQUBBCCBEkoSCEECJIQkEIIUSQhIIQQoggCQUhhBBBEgpCCCGCJBSEEEIESSgIIYQIklAQ\nQggRJKEghBAiSEJBCCFEkISCEEKIIFO4CwhVS4sHTYucG7parQm4XB3hLqOPSKwJIrMuqSk0UlPo\nIq0uo9FASkr8oJ83YkJB0/SICgUg4uqByKwJIrMuqSk0UlPoIrWuwZDuIyGEEEESCkIIIYJGTPdR\nf3Rdp6WlCa+3G7i0p22NjUY0TbukrzmQ0GsyYDbHkJKSjsFgGPa6hBAjR0ihUFNTw9q1a3G73SQn\nJ1NSUkJeXl6ffVwuF/fffz8OhwO/38+8efN46KGHMJlMbN68mR07dmA0GomKiuLee+9lwYIFF118\nR0crBoOBzMxcDIZLe9JjMhnx+yMrFEKtSdc13G4nHR2tJCYmX4LKhBAjRUgt6fr16ykuLuYvf/kL\nxcXFrFu37rx9nnrqKfLz8yktLeW1117j0KFD7Nq1C4CCggJefvllSktLeeyxx7j33nvp7u6+6OK7\nujpITEy+5IEw0hkMRhITU+jqipwrJYQQkWHA1tTlclFRUUFhYSEAhYWFVFRU0Nzc3Gc/g8GAx+NB\n0zS8Xi8+n4/MzEwAFixYQGxsLABTp05F13XcbvdFF69pKooyonvAwkZRTGiaGu4yhBARZsAW1eFw\nkJmZiaIoACiKQkZGBg6Hg9TU1OB+q1ev5q677mL+/Pl0dXVxyy23MGfOnPOO9+qrrzJ+/HiysrKG\n5A1In/iFkX83IUYHXddpbuvhlNNDndPDKWcHdU4Pqgab1ywe9PGG7GP2zp07mTp1Ki+88AIej4dV\nq1axc+dOli1bFtznvffe48knn+TZZ58d9PGt1oTztjU2GjGZwtd1FM7X/jSDqcloNJKenjiM1Zxx\nqV5nMKSm0EhNoRvOunRdx+nu5kRDO7UNbdTWtwe+Gtrp6vEH90tJjGZ8ViLTJ1kv6HUGDAWbzUZD\nQwOqqqIoCqqq0tjYiM1m67Pf1q1beeyxxzAajSQmJrJ48WL27dsXDIWPPvqI++67jy1btjBp0qRB\nF+pydZw3MUTTtLAN9o7kgebTNE2jqal9GCsKSE9PvCSvMxhSU2ikptANVV26ruPu8AY+8Td5gmcA\ndS4PXT1nunyT4qLITovn6hlZZKfHk5MWT3ZaPAmxUUBgRvOFGDAUrFYrdrudsrIyioqKKCsrw263\n9+k6AsjNzeWtt96ioKAAr9fL3r17uf766wHYv38/9957Lz/96U+ZMWPGBRU6Emzc+BC1tcfx+bzk\n5Izj/vvXkZSURFnZdl566fcAREVFsWnTj0lNtfLOO2/z7LNP4/f7MRoNPPjgRiZPnhLmdyGEuBR0\nXafV4w00+mc3/k4PnWd98k+IjSInLZ4rZ2SRk3am8U+MMw9LXQZd1we8wL+6upq1a9fS1tZGUlIS\nJSUlTJo0iVWrVnH33Xczc+ZMamtrWb9+PU6nE1VVmTdvHg8++CAmk4mVK1dy6tSp4MAzwKZNm5g6\ndWrIhfZ3plBff5ysrAkAvHPAwZ79jpCPNxjzC2xcM7PvmVF/n8pPX7IL8PTTW3r/Ha6ipORRtmz5\nFVZrGp2dnSiKQkNDPXfeeTubNz/DuHHj8Xq9+P0+4uIGf6+Sz6rps5z97zecIvGTndQUGqkpdJ9W\nl67rtHX6qGvqOKvfP/Dd032m8Y+PMQUa/PSEYMOfkxZPUvyFNf5Go6HfbveBhDSmkJ+fz0svvXTe\n9meeeSb48/jx43nuuef6ff62bdsGXdhItHNnGbt27cTv99HV1c24cePRNI1ly76E1ZoGQFxcHADv\nv7+PK6+8mnHjxgNgNpsxm4cn+YUQl0Zbp7fPp/7T3zu6fMF94qJNZKfHM3daRrDhP934R8IFIKPm\nes5rZp7/af5SKi//iFdf3cYvfvEsKSkp7Nq1k9de+2PY6hFCDK1urx93hxd3ew9uTw/udi/ujh5a\nPV5a2rppcHfR2uEN7h8brZCdFs/nL0sjO+3Mp//khMho/D/NqAmFcGtvbyc+PgGLxYLX6+VPf3oN\ngKuuuoaSkkcpKvoKqanWYPfRFVdcyQsv/JoTJ2qHrPtICDF4pxv71o4eWjoCjX2rp+esbYHGv8d7\n/rwes8lIckI0lgQzV0zPIjXBHGz8UxKjI7rx/zQSCkPkyiuvZteuP/Nv//YVLJZkZs/+HBUVh/j8\n5+dy663/wT33rMZgMGI2R1FS8mPGjRvPmjUPsn79/aiqhqIYefDBjeTnTw73WxFiVOj2+mntbdBb\nOnqCP5/ZFmj0u/tp7KNMRpITzCQnRDM+I4GZk1JJSYgOBkByQjTJCWZio03Bhj9SxzoGK6SB5kgw\n0EDzpTYaLkmVgWapaSCRWFNiUixVx1y4OwKf5s9u6M/eNlBjb+lt2FPOaugtCdGknNPYhyrS/q2G\ndaBZCCHCQdd1Glu6OHKylapTbqpOtVHn9Jy33+nG3pIQTW5GApdPSg1+mr/Yxn6skVAQQkQMn1/j\neEM7VSdbOXLSTfWpVto6A1fuxEWbmJxr4do544g1GUhOjA42/HHS2A8ZCQUhRNi0d3qpOtUaCIFT\nrRxztONXA12gGcmxXD7JyuRcC1NyLNjS4jEaDBHXTTPaSCgIIS4JXdepb+4MBkDVyVbqmzsBUIwG\n8rISWTInh8k5FibnWLAkRIe54rFJQkEIMSx8fpUaR3vwTKDqVGtwEld8jInJORaumZnFlNxk8rIS\nMUcpYa5YgISCEGKItHnO7gpyc7y+Hb8auGIwMzWO2ZPTmJwbOAvIssZhlDGAiCShIIQYNE3Xcbg6\nqTrpDnYHNbZ0AWBSDORlJXHd3HFMybGQn2shaZhu3iaGnoSCEGJAXp9KjaONqlOtHDnZSvWp1uDN\n3BJio5iSa2Hh7Gwm51jIy0okyiRdQeGka360znaQeQojy5133s6//dutXHPNgnCXIkRQV4+f+uZO\n6pwenO3H2X+kidqGdtTeyaM2axyfvyw9cFVQbjKZKbFyOWgY6LqG7nGjtdb3fjUEv+ttTZiSUuHO\npwZ93FETCr5/voOv8q1hOXbU1C8Qddk1w3JsIcJB13XaO304XB7qXJ04nJ7gzy3tPcH9zCYjeVmJ\nLL1ifHA84PQiLmL46bqO3tOB7j6/4ddaG0A9cwM+FDNGSyZKai7GiXOJysi7oNccNaEQbs8//yva\n2lq5++7/DUBrq5vi4pU8+OBGXnjh13i9Paiqyr//+ze57rqlIR3T7/ezZs09tLa20tPTw/TpM7jv\nvgeIigr8T/mb3zzH66/vxGAwEhsby9NPB5Y5/bRFfcTYo+k6za3dgYbf5ekTAmffyz86SiHLGse0\n8cnYrPHYrPFkp8UxfUoGLc3nzyAWQ0v3dqG1NaC568987w0AvJ1ndjQoGJLSMVoyicqZjtGSidGS\nhdGSiSE+BYPhzHK8w7by2kgRddk1Yf00v2xZIf/1X7exevV3MZlMvP76Tq655gtcfnkBW7b8CkVR\naG528a1v3coVV1xFUlLSgMdUFIX16x/FYklG13UefXQ9f/rTdlas+Cp//nMZe/a8xVNPPUtcXDyt\nrW6MRiP/+Md7/OY3z523qI8Y3fyqRkNLV/ATv8PVSZ3LQ31zJ17fmfthJcRGkW2NY+60jEDDb43D\nZo0nJSm636uBTEp41yHXVR96jwe9pxN6POg9HjoawedRMURFYzBFQ1QMhqhoMJkxRMUEvhsib/10\nXfWhtTWitdajn/2J312P3tXaZ19DgjXQ8E++srfhDzT+hsQ0DMbhbbZHTSiEW1ZWFnl5+bz77jvM\nn7+QHTvKuPvu7+F2t/D44w9z8mQtimKira2V2trjXH75zAGPqWkav/vdVt599+9omkp7ezsxMTEA\nvPPO26xYsTJ4q22LJbDi29697/S7qI8YHXq8Ko5mDw5noNF3uAJ9/03urmCfP4A1KRqbNZ6p41Kw\npcWRbY3HZo0btiUcP4uuaeDtDHSD9HT2NvLnfnWC9/zt+L3nHa8rlBdVzIGgiIrGYIqBKDMGU3Rv\naERjiDKD6XSYRJ8TMObebTHn/C4ajJ99Ow1d09A7nP129egdTjjr/qOGmESMliyUcQUYkzMxJmVi\nTM7CmJQReL0wkVAYQjfeWMif/1yGzZaDx9PBrFmf4557VnPNNV/gscf+B4PBwNe//hW83p6BDwa8\n/vpO9u//mC1bniEuLp4XX3yWEydqh/ldiEjQ3ukNftp3OM90/bjazvy3YzQYyEiJxWaNY87U9EDD\nnxZHVmocMeah/V9b13XwdQUb8PMa77MfezvRuz3ovY083gGacZMZQ3R88MuYmA5pEzFEx/XZfvor\nNdNKc5Mb3d8Dvh50Xzf4vb2Pu9F9PWd+d853rceJ7vMG9vP3gL+nT0M9IIOxN2h6A6Q3NFCiONHT\niq+5HrQz3XJExQQa/ox8jFOu7tvdEx2Za6dIKAyhhQsX87OfPcHvf7+VL36xEIPBQHt7OzabDYPB\nwPvvv8upUydCPl5HRzsWSzJxcfF0dHTw+us7mTZtOgDXXLOAV1/dxsKFi4LdR1Zr6qcu6hMdLbcM\niDR+VaPJ3UVDSxcNzZ24O33UnHRT5+rss3yj2WQkyxrHlNxkvtDb3WNLiyczJXbA7h1d1wMNpq8L\nvN3ovi50b1egIfV29T7uDjT4vb+n9/e6t4sutRu1swPd2wn6Z9yW3agEG22i4zHEJ2NMye63USf4\nc2+jrwxu4NqcloiiWwb1nE+j6zqovrMCJhAUgaDp6RswnxU+vi6iUrMx5BRgOLvhj7WMuCuzJBSG\nUExMTG/XUSl/+ENg5bU77riT//N/Svj1r5/Gbp9Ofv6UkI+3bFkhb7/9FsXFK0lJSWXWrM/R09PT\n+7sv0dTUyO23/ycmk4nY2Fh++ctff+qiPhIK4aFpOs1t3dS3dNLQHGj8T4eAs7Ub7axPqYlxUWSm\nxgWWb0yNIdtiIivRQHK0Bv7TjXgjurcL6rpQj3Xj79O4n27szzT++LpC+yRsUMAcg8EciyEqFkNU\nDIbYJKITc/ASjcEc10+jfrphT+jtxx9ZjR8QqNlkxmAyQ0ziRR1rtNyoTxbZuUCyyE7oIvF/lqGs\nSdd13B1eGls6qT+r0W9o6aKxpRO/qhFn6CHR0E2q2UtugkpmnIo1ugeL4iWBLqJVDyatC7W7M9CY\nq76BXxh6+8ADjTlRsb2Nekygge99TFRMcHvfx7Fwen8lqt9GfbT/7YZSpNUli+wIMYx0Xaejyxds\n8BubO2hxNtPldtHT7iZG85Bo7CbR0E2a0s1UsxeL0kN8ahfRmgfD2V0vGtABeIwYYhIxxCVhiLUQ\nbcnBq5nONO6nG+zTjfjpBj3Y2EdH5FU2YmQLKRRqampYu3Ytbreb5ORkSkpKyMvL67OPy+Xi/vvv\nx+Fw4Pf7mTdvHg899BAmkwlVVXn00Ud5++23MRgM3H777dx0003D8X5GpP/5n8c4dOhgn22KovDr\nX/8mTBWNTbrqo8vdjKupiTanE09LM96OFrTONow97cTqnSQauplk7OJyQw/By8DPusBLN5owxlkw\nxCZhiE3FGBto8AOPT39ZAkEQHd+nUY+0T5pibAopFNavX09xcTFFRUVs376ddevW8eKLL/bZ56mn\nniI/P5+nn34an89HcXExu3bt4sYbb6S0tJTa2lp27dqF2+1mxYoVXHXVVeTm5l70G9B1fUT2ZZ7t\nvvseuOSveal6DXVdR9dUdNUHmhYYrNRUdP3Mz4Hvgce6poF+7razH6tn7XfWttP7nndMFV3T+xxT\n9fup8XbR5mxC62zF6O3A7O8gmsDlj8m9X6d5icIbE48WnYgSl4Y5MRmzJRUl7kxjb+xt6ImSWz6I\nkW3AUHC5XFRUVPDcc88BUFhYyCOPPEJzczOpqanB/QwGAx6PB03T8Hq9+Hw+MjMzAdixYwc33XQT\nRqOR1NRUrrvuOnbu3Mm3v/3tiyreaFRQVT8mk0y7HyxV9WM0Du2kNl3X0TtcqI1HURur0RqPojqP\n06Gef615OGm6gS49Co8eS7sWQ7fRgh6dizHOQnRiMnHJVixpaaSmp2NOSg7rNeNCXGoDhoLD4SAz\nMzM4K1ZRFDIyMnA4HH1CYfXq1dx1113Mnz+frq4ubrnlFubMmRM8RnZ2dnBfm81GfX39RRcfG5tA\ne7ub5GSr9K0Ogq5rtLe3EBs7+EGoPsfxdqE21aA2HkVrrEZtPHpmZqZiwpiWR5R9IQmpVjxdfjAY\nMRiNgWu9g9+VwN+u9+ezfxfY99xtZz9WzjumjhFnu5ea+g6q69qpquvA0dyFihGjYmRCloUp45K5\nfHI6cSYj9pRYYqNlaE2I04bs/4adO3cydepUXnjhBTweD6tWrWLnzp0sW7ZsSI7f3yi61RrPiRMn\ncDpPDWr+yVhnMEB8fDzjxuVgNIYWprqm4m06QU/dEXpO/ZPuuiP4mk4CgX/4qNRs4ifPJjp7CjHZ\nUzBnTuhz/XnKcLwRAtf6Hz3VyifHmqmocVJR04y794ZuCbFR2CdaufYqK/a8VKaMS4741b3S0y/u\nssjhIDWFLlLrGowBQ8Fms9HQ0ICqqiiKgqqqNDY2YrPZ+uy3detWHnvsMYxGI4mJiSxevJh9+/ax\nbNkybDYbdXV1FBQUAOefOYSiv0tSAeLiUomLS+3nGcMrEgcFB1uTy/XpNzrTPC1nuoAaq1GbjgVm\nfwJEx6Nk5GOeMwclIx8lfSKGmEBoe3u/aO4Gui+ors/S1eOnuq53da+TrVTXtQbv7ZNmicE+PoUp\nuRam5J5Z6P20VveZG4uNhr/fpSA1hS7S6hq2S1KtVit2u52ysjKKioooKyvDbrf36ToCyM3N5a23\n3qKgoACv18vevXu5/vrrAVi2bBkvvfQSN9xwA263m927d/Pb3/520MWK4aH7elCdx4JdQGpjNbqn\nJfBLo4LROoGoqQtQMiahZORjSMq4ZIOpLe09HDnp5sjJVo6cdHOisQNdD5ztjM9IZEFBdm8IJJOS\nKH3/QlyskLqPNmzYwNq1a9myZQtJSUmUlJQAsGrVKu6++25mzpzJAw88wPr161m+fDmqqjJv3jxu\nvvlmAIqKiigvL+eGG24A4Dvf+Q7jxo0bprckPouua2huB1pDbwA0VaM1nwrewsCQmI6SNbU3ACZh\ntI4PzPa8BDRdp87p6T0LCASBszVwtmGOMpKfbWH51XlMyU1mUnaSjAUIMQxG9IzmcIq0U0Xovyat\ns/WsLqCjqI01gVsfAJhjUdInoWTmBwIgfRLG2IFv6T0UdQH4/Co1jvZgAFSdbKWzJ3AzsaR4c/AM\nYEquhXEZCUN6G+eR8vcLN6kpdJFWl8xoFmi+HtT6I8EuILWxGr3DFfilQcFozSVqylWBAMiYFLg/\n+yW8aqujy8eR0wu9n2zlWH0bfvXMEo9zp6UzJTeZybkWMpLlen8hwkFCYQTTNRWtqQb/qUOopypo\nb6gO3rbXkGANdAFdfh3GjMkoaRMuWTfQaV09fj6uclLbVM3+I004XIGBXsVoIM+WyHVzxzElx0J+\nroWkMNznXwhxPgmFEUTXdfTWevwnD6GeOoS/7nBvV5ABY9oELPMK6UkcHzgTiEse8HjDQdU0DtW0\nsPdQPR/9swmvXyM+xkR+joWrZmQxJdfCRFtSxF8aKsRYJaEQ4bTOVtS6it4gqED3NAOBAeGo/Hko\nudMxZU/HEJOANUx9mrquc7yhnb0HG9j3SQNtHi/xMSaunmnjqhmZXDkrF5er45LXJYQYPAmFCKP7\nelAdlb1dQofQmk8GfhEdjylnOkrOlzHlTMeYlBHeQgFXazfvVtTz94P1OFydKEYDsyancdWMLAry\nrUSZAuMVF7qAuBDi0pNQCLMz4wIVqKcOoTZUBW7opphQsi7DfMVNmHJmBC4NDXH28XDq6vHzj8ON\n7D1UT2WtGx2YnGvh35dOZe60DBJi5T5UQoxkEgqXWHBcoHdw2F/3Se8atgaMaeMxz1yKkjMDJWvK\nJR8Y/jR+VeNQTXNgnOCIE59fIyMllqL5E7ny8iwykmPDXaIQYohIKFwCZ8YFAmcDZ8YF0oiadAVK\n7gyUbDvGi1wOcCjpus6x+nb+frCe9z5poL3TR0JsFPMLbFw9I4tJ2UlyyagQo5CEwjDoOy5QgdZ8\nIvCL6HhM2XaUnOWYcmdExLjAuZzuLvZWNLD3YD31zZ2YFAOzJ6dx1eVZzJxkHdIJZEKIyCOhMAQG\nHhf4KqacyyNmXOBcnd0+/lHZxN8P1vPPE24ALsu1sPSKqfzLtAziYmScQIixQkLhAui6jtdVh/fQ\nvnPGBcCYNqF3XGA6StZlETMucC6/qnHgqIu9B+v5uMqFX9XITI3jXxdM5MoZWaTLOIEQY5KEwiDo\nuo568gA9H75GR0MVcNa4QM4MlJzIGhc4l67rHHW0sfdgPe990khHV2CcYOHsbK6+PIu8rEQZJxBi\njJNQCIGu66jHP6bno9fQmmowxKdivf4/6bbaMSSmR3xD2uTuYu+hevYeaqChuROTYuRzUwLjBJdP\nTJVxAiFEkITCZ9B1DX/NB3g/KkVz1WJITCf6C/9J1JRrsGSl4I2gOyKey9Pt4/1PGvn7oXqqTgaW\nyJw6LpkvzhvP3KkZxMXIn14IcT5pGfqhaxr+o+8FwqDlFAZLFjHXrsI0+crAGsERyufX+PCfTew9\nWE95tRO/qmOzxrFy4STmTc8kzSLjBEKIzyahcBZdU/FXvRsIg9Z6jCnZxCz+X5gmXRGRVw2d5vNr\n/PWDk/x5Xy3tnV6S4qK49nM5XH15FhMyZZxACBE6CQVAV/34jryD96My9PYmjNZxxFz3HUwT51zS\n9QYGS9d1Pqhs4g9vVuFs7ebz0zL4wswsZkxMRYngEBNCRK4xHQq66sNX+Tbej/+E3uHCmD6RmKuK\nUSbMjvhP10fr2vj9G0eoOtlKTno83/vaLBZdkRdRKz8JIUaeMRkKur8H3yf/D2/5DvRON8bMycTM\nvw1l3MyIDwNXazfb3qrm3UMNJMVFcduyqcwvsMmZgRBiSIypUNB93fgq3sS7/8/oXW0otqmYF92O\nkm2P+DDo6vHz533H+ct7J9B1+NJVE7jxygmyeL0QYkiNiRZF93bhPbQb3/6/oPd0oOTMwPz5L2Oy\nTQ13aQPSNJ09Bxy88tZRWj1erpyeyVcWTpIriYQQw2JUh4Le48F78HW8B3aBtxNlXAHRn/8ySubk\ncJcWkopjzfz+r1WcbOogPyeJO78yk/wcS7jLEkKMYiGFQk1NDWvXrsXtdpOcnExJSQl5eXl99lmz\nZg2VlZXBx5WVlWzevJklS5bgcrm4//77cTgc+P1+5s2bx0MPPYTJNDyZpHW349v/F7yH/gq+LkwT\nPof5819GSZ84LK831BwuD394o4ryahdplhj+V9EM/mVaRsR3cQkhRr6QWuX169dTXFxMUVER27dv\nZ926dbz44ot99tm0aVPw58OHD3PbbbexYMECAJ566iny8/N5+umn8fl8FBcXs2vXLm688cYhfCuB\ndQu8+3fiq3gD/F5Mk+Zi/tyXUazjhvR1hktHl4/tb9fw5kenMEcZuenafK6bm0uUKXInzAkhRpcB\nQ8HlclFRUcFzzz0HQGFhIY888gjNzc2kpqb2+5yXX36Z5cuXYzYH7hBqMBjweDxomobX68Xn85GZ\nmTlkb0LztOAt34Hvk/8Hmg9T/jzMn1uOkpIzZK8xnHx+jTc+PEnpO8fo8vq5dnYORfMnkhQfmXdY\nFUKMXgOGgsPhIDMzE0UJfFpVFIWMjAwcDke/oeD1eiktLeX5558Pblu9ejV33XUX8+fPp6uri1tu\nuYU5c+YMqlCrNeG8bf7WJtx7X8Xz8W7QNBJmLiT56q9gtmYP6tgXKj394u6Iqus6ew84eL6sAofL\nw5xpGfzn8hlMyEoKW03DJRLrkppCIzWFLlLrGowh79TfvXs32dnZ2O324LadO3cydepUXnjhBTwe\nD6tWrWLnzp0sW7Ys5OO6XB1omg6A1taI9+MyfP98B4Coy+Zjnv0lDEkZtGrAJZjAlZ6eeFETxWoc\nbfzfvx7hnydbyUmL53s3z+LySVaACz7uxdY0XCKxLqkpNFJT6CKtLqPR0O+H6YEMGAo2m42GhgZU\nVUVRFFRVpbGxEZvN1u/+27ZtY+XKlX22bd26lcceewyj0UhiYiKLFy9m3759gwoFAM1dT8/HpfiP\n7AWjkahp12KefSPGBOugjhNOzW3d/PGto/z9YD2JcVH8+9KpLJglk8+EEJFhwFCwWq3Y7XbKysoo\nKiqirKwMu93eb9dRfX09H3zwAU888USf7bm5ubz11lsUFBTg9XrZu3cv119//aAK7f77b+k58DoY\no4iacR3mWV/EGJ8yqGOEU7fXz859tezcV4umw41XTuBLV8nkMyFEZAmpRdqwYQNr165ly5YtJCUl\nUVJSAsCqVau4++67mTlzJgCvvPIKixYtwmLpey39Aw88wPr161m+fDmqqjJv3jxuvvnmQRWqnjyE\nueCLRM1cijFu5Fyrr2k67xx08Me3jtLa4eUKewZfXZhPmix3KYSIQAZd1/VwFxGKproGiIoLdxlB\nofQffnK8hf/71yPUNnYwKTuJry+ZwuRhnHwWaX2ap0ViXVJTaKSm0EVaXcM2phApjNHxwYHmSFff\n3Mkf3qji4yon1qRo/uvLM7jCLpPPhBCRb8SEwkjQ0eXjtXdqePPDU0SZjKxcOInr547DHCWTz4QQ\nI4OEwhDwqxpvfHiK0ndq6OwNfH27AAAXs0lEQVTxs3BWNkULJmGRyWdCiBFGQuEi6LrOR0ec/OHN\nKhpbupgxMZWvLZ5Mbvrg+/GEECISSChcoKqTbn65rZzDtW6y0+K59+ZZzJw0cuZLCCFEfyQULsD7\nhxt5avtB4mOiuPWGy/jC7GyZfCaEGBUkFC7A2+V1ZKbG8dCtc4mLkX9CIcToIR9vB6mrx8/h2hau\nvNwmgSCEGHUkFAap4lgLflXniulZ4S5FCCGGnITCIJVXOYmNNmGf2P9aEkIIMZJJKAyCpuvsr3Yy\nc1IqJkX+6YQQo4+0bINwzNFOW6ePWZPTwl2KEEIMCwmFQfi4yonBgMxHEEKMWhIKg7C/ysmUHAsJ\nsVHhLkUIIYaFhEKImtu6qW3skK4jIcSoJqEQovJqF4CEghBiVJNQCFF5lZP05Bhs1shZ6EcIIYaa\nhEIIenwqnxxvYdbkNFkoRwgxqkkohOCTYy34/Jp0HQkhRj0JhRB8XOUkxqwwdVxyuEsRQohhJaEw\nAF3XKa92cvlEmcUshBj9QrrNZ01NDWvXrsXtdpOcnExJSQl5eXl99lmzZg2VlZXBx5WVlWzevJkl\nS5YAsGPHDn7xi1+g6zoGg4HnnnuOtLTI74453tBOa4dXuo6EEGNCSKGwfv16iouLKSoqYvv27axb\nt44XX3yxzz6bNm0K/nz48GFuu+02FixYAMCBAwf4+c9/zgsvvEB6ejrt7e2YzSNj/eLyKhcGYGa+\nzGIWQox+A/aHuFwuKioqKCwsBKCwsJCKigqam5s/9Tkvv/wyy5cvDzb8zz//PN/85jdJT08HIDEx\nkejo6KGof9iVVzmZlJNEUtzICDEhhLgYA4aCw+EgMzMTRVEAUBSFjIwMHA5Hv/t7vV5KS0tZuXJl\ncFt1dTUnTpzglltu4V//9V/ZsmULuq4P0VsYPi3tPRyrb2dWvnQdCSHGhiFfOmz37t1kZ2djt9uD\n21RVpbKykueeew6v18u3v/1tsrOzWbFiRcjHtVoThrrUAX1YHTgbWnTFBNLTE8/7fX/bwi0Sa4LI\nrEtqCo3UFLpIrWswBgwFm81GQ0MDqqqiKAqqqtLY2IjNZut3/23btvU5SwDIzs5m2bJlmM1mzGYz\nS5YsYf/+/YMKBZerA027tGcXez46iTUpmjgFmpra+/wuPT3xvG3hFok1QWTWJTWFRmoKXaTVZTQa\nLujD9IDdR1arFbvdTllZGQBlZWXY7XZSU89feay+vp4PPviA5cuX99leWFjInj170HUdn8/Hu+++\ny7Rp0wZd7KXk9alUHG+WWcxCiDElpAvvN2zYwNatW1m6dClbt25l48aNAKxatYoDBw4E93vllVdY\ntGgRFoulz/O/9KUvYbVaufHGG1mxYgWTJ0/mq1/96hC+jaF3uNaN1yezmIUQY4tBHwkjvlz67qPf\n/KWSvx+s56ffnU+USTnv95F2qgiRWRNEZl1SU2ikptBFWl3D1n00Fp2exTw9L6XfQBBCiNFKQqEf\nJxo7aG7rka4jIcSYI6HQj+CCOjKLWQgxxkgo9KO8yslEWyKWhJEx61oIIYaKhMI5Wj1eaurapOtI\nCDEmSSic40C1Cx3k1hZCiDFJQuEc5VVOUhKjGZ956W+rIYQQ4SahcBafX+PgsWZm5VtlFrMQYkyS\nUDhL5YkWerwqBTKeIIQYoyQUzlJe5cJsMjJ9Qkq4SxFCiLCQUOil6zrlVU7sE1IwR8ksZiHE2CSh\n0KvO6cHZ2s2sKdJ1JIQYuyQUep2ZxSyhIIQYuyQUen1c5WR8ZgIpiTKLWQgxdkkoAO2dXqpPtTJb\nrjoSQoxxEgrAgaMudB25tYUQYsyTUCBwKaol3syErJG/6LYQQlyMMR8KflXjYI2LgnwrRpnFLIQY\n48Z8KBw54aarR5XxBCGEQEKB8moXJsWIPU9mMQshxJgOBV3X+bjKybQJycSYTeEuRwghwm5Mh0J9\ncyeNLV3SdSSEEL1CCoWamhq+9rWvsXTpUr72ta9x7Nix8/ZZs2YNRUVFwa9p06bx17/+tc8+R48e\nZdasWZSUlAxJ8RervCowi7lA1mIWQggAQuozWb9+PcXFxRQVFbF9+3bWrVvHiy++2GefTZs2BX8+\nfPgwt912GwsWLAhuU1WV9evXc9111w1R6RevvMpJbnoCaZbYcJcihBARYcAzBZfLRUVFBYWFhQAU\nFhZSUVFBc3Pzpz7n5ZdfZvny5ZjN5uC2p59+mmuvvZa8vLyLr3oIeLp9HDnZyqzJcpYghBCnDRgK\nDoeDzMxMFCVwO2lFUcjIyMDhcPS7v9frpbS0lJUrVwa3HT58mD179vAf//EfQ1P1EDhw1IWm6zKe\nIIQQZxnyS252795NdnY2drsdAJ/Pxw9/+EMef/zxYLBcCKt1aNdMrjzxTywJZv6lIAfFeGGT1tLT\nI28GdCTWBJFZl9QUGqkpdJFa12AMGAo2m42GhgZUVUVRFFRVpbGxEZvN1u/+27Zt63OW0NTURG1t\nLbfffjsAbW1t6LpOR0cHjzzySMiFulwdaJoe8v6fRdU0/vFJPbMnp9Hs6rigY6SnJ9LU1D4k9QyV\nSKwJIrMuqSk0UlPoIq0uo9FwQR+mBwwFq9WK3W6nrKyMoqIiysrKsNvtpKamnrdvfX09H3zwAU88\n8URwW3Z2Nvv27Qs+/tnPfkZnZyc/+MEPBl3sUKk62Yqn2y83wBNCiHOEdEnqhg0b2Lp1K0uXLmXr\n1q1s3LgRgFWrVnHgwIHgfq+88gqLFi3CYrEMT7VDpLzahWI0MGPi+cEmhBBjWUhjCvn5+bz00kvn\nbX/mmWf6PL7jjjsGPNZdd90VYmnDp7zKybTxycRGyyxmIYQ425ib0dzQ0onD1UmBdB0JIcR5xlwo\nnJ7FLOMJQghxvjEYCk6y0+LJSJZZzEIIca4xFQqd3X7+ecLNLLnXkRBC9GtMhcKhY82omi5dR0II\n8SnGVCiUVzmJjzGRn5MU7lKEECIijZlQ0DSd/dWBtZgV45h520IIMShjpnU8WtdGR5dPuo6EEOIz\njJlQ+LjKiWI0cLnMYhZCiE81ZkKhvNrJlFwLcTFR4S5FCCEi1pgIBae7i1NNHuk6EkKIAYyJUCiv\nDsxilgV1hBDis42NUKhykpkaR2ZqXLhLEUKIiDbqQ6Grx8/h2hZmy1rMQggxoFEfChXHWvCrOrPy\npetICCEGMupDobzKSWy0icm5kb3wjxBCRIJRHQqarrO/2snMSamYlFH9VoUQYkiM6pbymKOdtk6Z\nxSyEEKEa1aHwcZUTgwFmTpJBZiGECMWoDoX9VU6m5FhIiJVZzEIIEYpRGwrNbd3UNnYwa4p0HQkh\nRKhGbSicnsUsl6IKIUToTKHsVFNTw9q1a3G73SQnJ1NSUkJeXl6ffdasWUNlZWXwcWVlJZs3b2bJ\nkiVs3ryZHTt2YDQaiYqK4t5772XBggVD+kbOVV7lJD05BptVZjELIUSoQgqF9evXU1xcTFFREdu3\nb2fdunW8+OKLffbZtGlT8OfDhw9z2223BRv+goICvvnNbxIbG8vhw4f5xje+wZ49e4iJiRnCt3JG\nj0/lk+MtLJydjcFgGJbXEEKI0WjA7iOXy0VFRQWFhYUAFBYWUlFRQXNz86c+5+WXX2b58uWYzWYA\nFixYQGxsLABTp05F13XcbvdQ1N+vT4614PNrcimqEEIM0oBnCg6Hg8zMTBRFAUBRFDIyMnA4HKSm\nnr9gjdfrpbS0lOeff77f47366quMHz+erKysQRVqtSaEvG/l36qJjTZxzefGEWUavmGT9PTEYTv2\nhYrEmiAy65KaQiM1hS5S6xqMkLqPBmP37t1kZ2djt9vP+917773Hk08+ybPPPjvo47pcHWiaPuB+\nuq7z7kEHM/JScLd4Bv06oUpPT6SpqX3Yjn8hIrEmiMy6pKbQSE2hi7S6jEbDoD5MB5830A42m42G\nhgZUVQVAVVUaGxux2Wz97r9t2zZWrlx53vaPPvqI++67j82bNzNp0qRBFxqq4w3ttHZ4petICCEu\nwIChYLVasdvtlJWVAVBWVobdbu+366i+vp4PPviA5cuX99m+f/9+7r33Xn76058yY8aMISq9f+VV\nLgzAzHyZxSyEEIMVUof7hg0b2Lp1K0uXLmXr1q1s3LgRgFWrVnHgwIHgfq+88gqLFi3CYul7R9KN\nGzfS3d3NunXrKCoqoqioqM/lq0OpvMrJpJwkkuLMw3J8IYQYzUIaU8jPz+ell146b/szzzzT5/Ed\nd9zR7/O3bdt2AaUNXkt7D8fq21m5cPi6p4QQYjQbVTOaDxyVWcxCCHExRlUofHzEiTUphpz0+HCX\nIoQQI9KoCQWvT6XieDOzJltlFrMQQlygURMKh2tb8PpkFrMQQlyMURMK5VUuoqMUpo1PDncpQggx\nYo2KUNB1nfJqJ9PzUogyKeEuRwghRqxREQonGjtobuthtnQdCSHERRkVoXB6QZ0CmcUshBAXZXSE\nQpWTibYkLAnR4S5FCCFGtBEfCq0eLzV1bcyaLGcJQghxsUZ8KByodqEjs5iFEGIojPhQKK9ykpIY\nzfjMwd83XAghRF8jOhR8fo2Dx5qZlS+zmIUQYiiM6FCoPNFCj1eVWcxCCDFERnQolFe5MJuM2Cek\nhLsUIYQYFUZsKOi6TnmVE/uEFMxRMotZCCGGwogNhTqnB2drN7OmSNeREEIMlREbCqdnMculqEII\nMXRGbCh8XOVkQmYiKYkyi1kIIYbKiAyF9k4v1adaZRazEEIMsREZCgeOutB15FJUIYQYYqZQdqqp\nqWHt2rW43W6Sk5MpKSkhLy+vzz5r1qyhsrIy+LiyspLNmzezZMkSVFXl0Ucf5e2338ZgMHD77bdz\n0003XXDR5VUuLPFmJmQlXvAxhBBCnC+kUFi/fj3FxcUUFRWxfft21q1bx4svvthnn02bNgV/Pnz4\nMLfddhsLFiwAoLS0lNraWnbt2oXb7WbFihVcddVV5ObmDrpgv6pxsMbF3KkZGGUWsxBCDKkBu49c\nLhcVFRUUFhYCUFhYSEVFBc3NzZ/6nJdffpnly5djNpsB2LFjBzfddBNGo5HU1FSuu+46du7ceUEF\nHznhpqtHlQV1hBBiGAwYCg6Hg8zMTBQlMEFMURQyMjJwOBz97u/1eiktLWXlypV9jpGdnR18bLPZ\nqK+vv6CCy6tdmBQj0/NSL+j5QgghPl1I3UeDsXv3brKzs7Hb7UN6XKs1AV3XOVDTzKwpaeTmJA/p\n8S9EenrkjWlEYk0QmXVJTaGRmkIXqXUNxoChYLPZaGhoQFVVFEVBVVUaGxux2Wz97r9t27Y+Zwmn\nj1FXV0dBQQFw/plDKFyuDk41deBweljy+RyamtoH9fyhlp6eGPYazhWJNUFk1iU1hUZqCl2k1WU0\nGrBaB7+kwIDdR1arFbvdTllZGQBlZWXY7XZSU8/vvqmvr+eDDz5g+fLlfbYvW7aMl156CU3TaG5u\nZvfu3SxdunTQxZZXySxmIYQYTiHNU9iwYQNbt25l6dKlbN26lY0bNwKwatUqDhw4ENzvlVdeYdGi\nRVgslj7PLyoqIjc3lxtuuIGbb76Z73znO4wbN27QxZZXOclNT8BqiRn0c4UQQgwspDGF/Px8Xnrp\npfO2P/PMM30e33HHHf0+X1GUYJBcqK4eP0dOtvLFK8df1HGEEEJ8uhEzo/lwbQuarsulqEIIMYxG\nTigcd5MYF8VEW1K4SxFCiFFrxIRCZW0LBflWjEaZxSyEEMNlxIRCZ49frjoSQohhNmJCQTEamDFR\nZjELIcRwGjGhkJ+dRGz0kE/AFkIIcZYREwrT5F5HQggx7EZMKNgnpIS7BCGEGPVGTChYk2QWsxBC\nDLcREwpCCCGGn4SCEEKIIAkFIYQQQRIKQgghgiQUhBBCBEkoCCGECJJQEEIIESShIIQQImjE3Ewo\nEm+ZLTWFLhLrkppCIzWFLpLqutBaDLqu60NcixBCiBFKuo+EEEIESSgIIYQIklAQQggRJKEghBAi\nSEJBCCFEkISCEEKIIAkFIYQQQRIKQgghgiQUhBBCBEX0bS5qampYu3Ytbreb5ORkSkpKyMvLC2tN\nJSUl/OUvf+HUqVOUlpZy2WWXhbUegJaWFtasWUNtbS1ms5kJEybw8MMPk5qaGta6Vq9ezcmTJzEa\njcTFxfHDH/4Qu90e1ppO+/nPf87PfvaziPgbLl68GLPZTHR0NADf//73WbBgQVhrAujp6eGxxx5j\n7969REdHM3v2bB555JGw1XPy5Em+853vBB+3t7fT0dHBe++9F7aaAN58802efPJJdF1H13XuvPNO\nbrjhhrDW9Le//Y0nn3wSv9+PxWLh8ccfZ9y4caE9WY9gt956q/7qq6/quq7rr776qn7rrbeGuSJd\nf//99/W6ujp90aJFemVlZbjL0XVd11taWvR33303+Pi///u/9fvvvz+MFQW0tbUFf3799df1FStW\nhLGaMw4ePKh/61vfipi/YaTUca5HHnlE/9GPfqRrmqbruq43NTWFuaK+Hn30UX3jxo1hrUHTNH3u\n3LnBv98nn3yiz549W1dVNWw1ud1u/YorrtCPHj2q63qg7fzmN78Z8vMjtvvI5XJRUVFBYWEhAIWF\nhVRUVNDc3BzWuubOnYvNZgtrDedKTk5m3rx5wcezZ8+mrq4ujBUFJCYmBn/u6OjAYAj/zcK8Xi8P\nP/wwGzZsCHcpEc3j8fDqq6/y3e9+N/h3S0tLC3NVZ3i9XkpLS1m5cmW4S8FoNNLe3g4Ezl4yMjIw\nGsPXtB4/fpy0tDQmTpwIwMKFC9mzZ0/IbWfEdh85HA4yMzNRFAUARVHIyMjA4XCEvVskkmmaxu9+\n9zsWL14c7lIAePDBB3nnnXfQdZ1f/epX4S6HJ598ki9/+cvk5uaGu5Q+vv/976PrOnPmzOF73/se\nSUlJYa3nxIkTJCcn8/Of/5x9+/YRHx/Pd7/7XebOnRvWuk574403yMzMZMaMGWGtw2Aw8JOf/ITV\nq1cTFxeHx+Ph6aefDmtNEydOxOl0sn//fgoKCigtLQUIue2M2DMFcWEeeeQR4uLi+MY3vhHuUgD4\n0Y9+xN/+9jfuvfdeNm3aFNZaPvroIw4ePEhxcXFY6zjXb3/7W1577TW2bduGrus8/PDD4S4JVVU5\nceIE06dP549//CPf//73ueuuu+jo6Ah3aQBs27YtIs4S/H4/v/zlL9myZQtvvvkmv/jFL7jnnnvw\neDxhqykxMZEf//jHPP7443zlK1/B5XKRlJQU/IA9kIgNBZvNRkNDA6qqAoH/SBsbGyOu6yaSlJSU\ncPz4cX7yk5+E9fS1PytWrGDfvn20tLSErYb333+f6upqlixZwuLFi6mvr+db3/oWe/bsCVtNQPC/\nabPZTHFxMR9++GFY64FATSaTKdh9O2vWLFJSUqipqQlzZdDQ0MD777/P8uXLw10Kn3zyCY2NjcyZ\nMweAOXPmEBsbS3V1dVjruvrqq/nd737HH//4R77xjW/Q3d3N+PHjQ3puZLUcZ7FardjtdsrKygAo\nKyvDbrdL19GneOKJJzh48CCbN2/GbDaHuxw8Hg8OhyP4+I033sBisZCcnBy2mm6//Xb27NnDG2+8\nwRtvvEFWVha//vWvmT9/fthq6uzsDPZH67rOjh07IuIKrdTUVObNm8c777wDBK4EdLlcTJgwIcyV\nwSuvvMLChQtJSUkJdylkZWVRX1/P0aNHAaiursblcoXcAA+XpqYmINCd/MQTT/D1r3+duLi4kJ4b\n0YvsVFdXs3btWtra2khKSqKkpIRJkyaFtaZHH32UXbt24XQ6SUlJITk5mT/96U9hrenIkSMUFhaS\nl5dHTEwMALm5uWzevDlsNTmdTlavXk1XVxdGoxGLxcIPfvCDsPcBn23x4sU89dRTYb0k9cSJE9x1\n112oqoqmaeTn5/PQQw+RkZERtprOru2BBx7A7XZjMpm45557WLhwYbjLYunSpTz44IN84QtfCHcp\nALz22ms888wzwQH5u+++m+uuuy6sNT344IN8+OGH+Hw+rrnmGh544IHgJc8DiehQEEIIcWlFbPeR\nEEKIS09CQQghRJCEghBCiCAJBSGEEEESCkIIIYIkFIQQQgRJKAghhAiSUBBCCBH0/wFArwYmOkrk\nggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQHV4aHG__1L",
        "colab_type": "code",
        "outputId": "5a4f3c84-86bd-46aa-c861-946c8dc2a470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "labels = sorted(set([x[0] for x in y_true.tolist()]))\n",
        "targets = encoder.inverse_transform(labels)\n",
        "\n",
        "y_pred = classifier.predict_classes(X_test)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=targets))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Accounting & Consulting       0.66      0.57      0.61       307\n",
            "             Admin Support       0.68      0.74      0.71      2082\n",
            "          Customer Service       0.69      0.45      0.54       128\n",
            "  Data Science & Analytics       0.47      0.21      0.29       259\n",
            "         Design & Creative       0.86      0.87      0.86      3805\n",
            "Engineering & Architecture       0.68      0.72      0.70       335\n",
            "           IT & Networking       0.67      0.38      0.48       356\n",
            "                     Legal       0.63      0.56      0.59        48\n",
            "         Sales & Marketing       0.72      0.62      0.66      1243\n",
            "               Translation       0.84      0.92      0.88       853\n",
            "  Web & Mobile Development       0.00      0.00      0.00         1\n",
            "Web, Mobile & Software Dev       0.84      0.90      0.87      5380\n",
            "                   Writing       0.88      0.82      0.85      2797\n",
            "\n",
            "                  accuracy                           0.81     17594\n",
            "                 macro avg       0.66      0.60      0.62     17594\n",
            "              weighted avg       0.80      0.81      0.80     17594\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwuUbsvL__1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data = data_subset_empty.sample(1000)['as_opening_title']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoLo5fm__1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data.index = range(len(new_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HQRsMN__1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_X = []\n",
        "\n",
        "for doc in nlp.pipe(new_data, n_threads=4, batch_size=10000):\n",
        "    new_X.append(doc.vector)\n",
        "\n",
        "new_X = np.vstack(new_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYC6DIG___1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = classifier.predict_classes(new_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCwbDqw1__1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.concat([new_data, pd.Series(predictions.tolist())], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yb1KIX0__1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result['category'] = encoder.inverse_transform(result[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGZ67rS4__1S",
        "colab_type": "code",
        "outputId": "7fc318c3-b31f-4668-9b56-1c2d5fff19d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "result['category'].unique()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Admin Support', 'Web, Mobile & Software Dev', 'Writing',\n",
              "       'Design & Creative', 'Legal', 'Sales & Marketing',\n",
              "       'IT & Networking', 'Translation', 'Engineering & Architecture',\n",
              "       'Accounting & Consulting', 'Data Science & Analytics',\n",
              "       'Customer Service'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPY8WRvp__1T",
        "colab_type": "code",
        "outputId": "15a800b1-99ff-4595-abcf-69827621f717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result[result.category == 'Writing']"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>as_opening_title</th>\n",
              "      <th>0</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USA Book reviewers needed. Simple, fast and ea...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SEO friendly Articles</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Ongoing Content Writers</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I Need a Full Time Writer for Various Blogs (S...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Gaming Blogger Ongoing Work - Farrukh</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>need help with basic Microeconomics theories</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Writer needed for 10 articles</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Native English Speaking Teacher</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>2 sets of 25 pages each - FastMed and Broadban...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Screenplay Review</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Buying guides for top product categories</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>International Writer - Cathy</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>Book review</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>Editor for 600 word picture book manuscript</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Article Writing/Blogger</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>VA - to prepare ad titles</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>Swedish Contributor</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>SEO content writing in German language about w...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Secret Mission</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>5 Articles about College Students and College ...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Editor--Why Am I Single?</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>Ebook Cover for short story \"The Monitor\"</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>Copywriting needed for a sales letter</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Arresting Power: Ideas for the Right and the Left</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>Looking for Greek Content Writers for various ...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>Written English Note Translated to Assamese in...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>Articles for blog</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>01262017_180191_Translation_Malay_1000 words</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>Content Writer Needed</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>technical writing</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>Blog post on legal issues -1 POST OUT OF POTEN...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>Medical Writer</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>Need ACX Narrator For My Books - I Pay $0.50 p...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>Article Writer</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>Web content article</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>04192017_181442_Translation_Indonesian_700 words</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>Need Marketing Copywriter For Software Campagin</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>Book editor for spelling only.</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>Reviews Assistant</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>Short sports related blog articles</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Creation of scientific bibliography</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>5,00</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>Birth Book Copy Editing</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>Creative Writer Needed For Web Development com...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>USA Dog Behavior Comment Issue</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>12 different articels</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>Women Entrepreneurs and Innovators</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>Blogger</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>Article Writer/Product Reviewer</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>*Urgent* 3000 words proofreading within 7 hour...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>Writer Wanted for Several Sites: Photography, ...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>1 Press Release and 1 Blog Article</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>redo vitamin c serum listing</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Ongoing Writer for Large Content Production Team</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>M. P</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>10,000 word \"romantic\" story needed.</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>Proofread and rewrite an Infographic</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>BIOLOGY</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>i need a reliable person to help with internet...</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Website content writing</td>\n",
              "      <td>12</td>\n",
              "      <td>Writing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      as_opening_title   0 category\n",
              "2    USA Book reviewers needed. Simple, fast and ea...  12  Writing\n",
              "11                               SEO friendly Articles  12  Writing\n",
              "15                             Ongoing Content Writers  12  Writing\n",
              "19   I Need a Full Time Writer for Various Blogs (S...  12  Writing\n",
              "66               Gaming Blogger Ongoing Work - Farrukh  12  Writing\n",
              "70        need help with basic Microeconomics theories  12  Writing\n",
              "73                       Writer needed for 10 articles  12  Writing\n",
              "79                     Native English Speaking Teacher  12  Writing\n",
              "80   2 sets of 25 pages each - FastMed and Broadban...  12  Writing\n",
              "82                                   Screenplay Review  12  Writing\n",
              "101           Buying guides for top product categories  12  Writing\n",
              "104                       International Writer - Cathy  12  Writing\n",
              "105                                        Book review  12  Writing\n",
              "126        Editor for 600 word picture book manuscript  12  Writing\n",
              "128                            Article Writing/Blogger  12  Writing\n",
              "132                          VA - to prepare ad titles  12  Writing\n",
              "134                                Swedish Contributor  12  Writing\n",
              "135  SEO content writing in German language about w...  12  Writing\n",
              "136                                     Secret Mission  12  Writing\n",
              "145  5 Articles about College Students and College ...  12  Writing\n",
              "148                           Editor--Why Am I Single?  12  Writing\n",
              "152          Ebook Cover for short story \"The Monitor\"  12  Writing\n",
              "159              Copywriting needed for a sales letter  12  Writing\n",
              "169  Arresting Power: Ideas for the Right and the Left  12  Writing\n",
              "184  Looking for Greek Content Writers for various ...  12  Writing\n",
              "185  Written English Note Translated to Assamese in...  12  Writing\n",
              "190                                  Articles for blog  12  Writing\n",
              "200       01262017_180191_Translation_Malay_1000 words  12  Writing\n",
              "203                              Content Writer Needed  12  Writing\n",
              "211                                  technical writing  12  Writing\n",
              "..                                                 ...  ..      ...\n",
              "834  Blog post on legal issues -1 POST OUT OF POTEN...  12  Writing\n",
              "837                                     Medical Writer  12  Writing\n",
              "839  Need ACX Narrator For My Books - I Pay $0.50 p...  12  Writing\n",
              "840                                     Article Writer  12  Writing\n",
              "849                                Web content article  12  Writing\n",
              "854   04192017_181442_Translation_Indonesian_700 words  12  Writing\n",
              "856   Need Marketing Copywriter For Software Campagin   12  Writing\n",
              "858                    Book editor for spelling only.   12  Writing\n",
              "860                                  Reviews Assistant  12  Writing\n",
              "863                 Short sports related blog articles  12  Writing\n",
              "865                Creation of scientific bibliography  12  Writing\n",
              "882                                               5,00  12  Writing\n",
              "895                            Birth Book Copy Editing  12  Writing\n",
              "909  Creative Writer Needed For Web Development com...  12  Writing\n",
              "914                     USA Dog Behavior Comment Issue  12  Writing\n",
              "916                              12 different articels  12  Writing\n",
              "920                 Women Entrepreneurs and Innovators  12  Writing\n",
              "936                                            Blogger  12  Writing\n",
              "939                    Article Writer/Product Reviewer  12  Writing\n",
              "941  *Urgent* 3000 words proofreading within 7 hour...  12  Writing\n",
              "946  Writer Wanted for Several Sites: Photography, ...  12  Writing\n",
              "948                 1 Press Release and 1 Blog Article  12  Writing\n",
              "952                       redo vitamin c serum listing  12  Writing\n",
              "964   Ongoing Writer for Large Content Production Team  12  Writing\n",
              "971                                               M. P  12  Writing\n",
              "972               10,000 word \"romantic\" story needed.  12  Writing\n",
              "981               Proofread and rewrite an Infographic  12  Writing\n",
              "986                                            BIOLOGY  12  Writing\n",
              "993  i need a reliable person to help with internet...  12  Writing\n",
              "995                            Website content writing  12  Writing\n",
              "\n",
              "[135 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    }
  ]
}